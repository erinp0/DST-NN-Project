{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the performance with and without the bright-dark filter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we shall compare the performance on the basic model (ran on just one epoch) with images which have been resized against images which have been resized and had the bright-dark filter applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained on resized images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(42)\n",
    "\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to replicate this notebook, change the paths below to the file paths where the unedited train and test npy files are stored on your desktop. They can be downloaded from [here](https://drive.google.com/drive/u/0/folders/1tg24731_oseORhm1v2AMW-mOtC2wW8IJ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_training_data = np.load('filter_denoised .npy')\n",
    "black_patch_data = np.load('black_patched_denoised.npy')\n",
    "white_patch_data = np.load('white_patched_training.npy')\n",
    "noisy_data = np.load('noisy_train_denoised.npy')\n",
    "same_patch_data = np.load('same_image_patched_denoised.npy')\n",
    "bd_training_label = np.load('32_filter_training_labels.npy')\n",
    "black_patch_label = np.load('32_filter_training_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CATEGORIES = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.concatenate((bd_training_data,noisy_data,black_patch_data,white_patch_data,same_patch_data),axis=0,dtype='float32')\n",
    "training_label = np.concatenate((bd_training_label,black_patch_label,black_patch_label,black_patch_label,black_patch_label),axis=0,dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the train validation split is performed. Note, the pixel values are normalised to be between 0-1 already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(training_data, training_label, test_size=0.3, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next section of code converts the labels by one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
    "y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the structure of the model is specified, e.g., the number of layers, number of neurons per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Dense(43, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimiser is defined here, as well as the number of epochs (which is specified as 1 for time-saving purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 200\n",
    "\n",
    "opt = tf.keras.optimizers.legacy.Adam(lr=lr, decay=lr / (epochs * 0.5))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the model is fitted, but not before data augmentation is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4289/4289 [==============================] - 631s 146ms/step - loss: 0.6227 - accuracy: 0.8213 - val_loss: 0.1829 - val_accuracy: 0.9446\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "history = model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('defence_no_classifier200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
