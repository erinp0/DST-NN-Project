{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the performance with and without the bright-dark filter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we shall compare the performance on the basic model (ran on just one epoch) with images which have been resized against images which have been resized and had the bright-dark filter applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained on resized images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(42)\n",
    "\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to replicate this notebook, change the paths below to the file paths where the unedited train and test npy files are stored on your desktop. They can be downloaded from [here]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('32_original_train_data.npy')\n",
    "training_label = np.load('32_original_train_labels.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CATEGORIES = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the train validation split is performed. Note, the pixel values are normalised to be between 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (27446, 32, 32, 3)\n",
      "X_valid.shape (11763, 32, 32, 3)\n",
      "y_train.shape (27446,)\n",
      "y_valid.shape (11763,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(training_data, training_label, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "X_train = X_train/255 \n",
    "X_val = X_val/255\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_valid.shape\", X_val.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"y_valid.shape\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next section of code converts the labels by one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27446, 43)\n",
      "(11763, 43)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
    "y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the structure of the model is specified, e.g., the number of layers, number of neurons per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Dense(43, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimiser is defined here, as well as the number of epochs (which is specified as 1 for time-saving purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 1\n",
    "\n",
    "opt = tf.keras.optimizers.legacy.Adam(lr=lr, decay=lr / (epochs * 0.5))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the model is fitted, but not before data augmentation is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 82s 94ms/step - loss: 1.0070 - accuracy: 0.7306 - val_loss: 0.0878 - val_accuracy: 0.9809\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "history = model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the test data is prepared and the model is used to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('32_original_test_data.npy')\n",
    "test_labels = np.load('32_original_test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  1, 38, ...,  6,  7, 10], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are compared to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 8s 20ms/step\n",
      "Test Data accuracy:  93.32541567695962\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = test_data\n",
    "X_test = X_test/255\n",
    "\n",
    "pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "#Accuracy with the test data\n",
    "print('Test Data accuracy: ',accuracy_score(test_labels, pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(test_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90        60\n",
      "           1       0.92      0.97      0.95       720\n",
      "           2       0.88      0.97      0.92       750\n",
      "           3       0.97      0.92      0.94       450\n",
      "           4       1.00      0.89      0.94       660\n",
      "           5       0.74      0.94      0.83       630\n",
      "           6       0.99      0.85      0.92       150\n",
      "           7       0.99      0.87      0.93       450\n",
      "           8       0.94      0.93      0.94       450\n",
      "           9       0.97      0.97      0.97       480\n",
      "          10       0.98      0.93      0.96       660\n",
      "          11       0.98      0.99      0.98       420\n",
      "          12       1.00      0.94      0.97       690\n",
      "          13       0.99      0.99      0.99       720\n",
      "          14       0.96      1.00      0.98       270\n",
      "          15       0.97      0.87      0.91       210\n",
      "          16       0.95      0.97      0.96       150\n",
      "          17       1.00      0.88      0.94       360\n",
      "          18       0.94      0.75      0.84       390\n",
      "          19       1.00      0.87      0.93        60\n",
      "          20       0.79      0.96      0.86        90\n",
      "          21       0.99      0.78      0.87        90\n",
      "          22       1.00      0.78      0.88       120\n",
      "          23       1.00      0.96      0.98       150\n",
      "          24       0.95      0.66      0.78        90\n",
      "          25       0.81      0.99      0.89       480\n",
      "          26       0.90      0.89      0.90       180\n",
      "          27       0.56      1.00      0.71        60\n",
      "          28       0.98      0.98      0.98       150\n",
      "          29       0.67      0.99      0.80        90\n",
      "          30       0.96      0.73      0.83       150\n",
      "          31       1.00      0.91      0.95       270\n",
      "          32       0.98      1.00      0.99        60\n",
      "          33       0.98      0.99      0.99       210\n",
      "          34       1.00      1.00      1.00       120\n",
      "          35       0.99      0.96      0.98       390\n",
      "          36       0.99      0.99      0.99       120\n",
      "          37       1.00      0.98      0.99        60\n",
      "          38       1.00      0.98      0.99       690\n",
      "          39       1.00      0.89      0.94        90\n",
      "          40       0.53      0.90      0.67        90\n",
      "          41       0.92      0.78      0.85        60\n",
      "          42       1.00      0.89      0.94        90\n",
      "\n",
      "    accuracy                           0.93     12630\n",
      "   macro avg       0.93      0.92      0.92     12630\n",
      "weighted avg       0.94      0.93      0.93     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained on resized and bright-dark filter images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the bright_dark filter is defined. It increases the brightness of dark images and darkens those which are too bright (perhaps due to camera flash). Note, the pixel values are normalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_training_data = np.load('32_filter_training_data.npy')\n",
    "bd_training_label = np.load('32_filter_training_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the bright-dark filter data has already been normalised to between 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.16470589, 0.23137255, 0.41568628],\n",
       "         [0.15294118, 0.21176471, 0.3764706 ],\n",
       "         [0.13725491, 0.2       , 0.30588236],\n",
       "         ...,\n",
       "         [0.16470589, 0.31764707, 0.53725493],\n",
       "         [0.19215687, 0.33333334, 0.53333336],\n",
       "         [0.26666668, 0.43921569, 0.6901961 ]],\n",
       "\n",
       "        [[0.18431373, 0.25882354, 0.41568628],\n",
       "         [0.16078432, 0.22745098, 0.35686275],\n",
       "         [0.1254902 , 0.20784314, 0.34509805],\n",
       "         ...,\n",
       "         [0.09019608, 0.21960784, 0.36470589],\n",
       "         [0.07450981, 0.19215687, 0.23921569],\n",
       "         [0.11764706, 0.26666668, 0.32941177]],\n",
       "\n",
       "        [[0.1882353 , 0.27843139, 0.44705883],\n",
       "         [0.14509805, 0.24705882, 0.37254903],\n",
       "         [0.10980392, 0.22745098, 0.38039216],\n",
       "         ...,\n",
       "         [0.10588235, 0.22352941, 0.34509805],\n",
       "         [0.07058824, 0.19215687, 0.23921569],\n",
       "         [0.07843138, 0.21176471, 0.26274511]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.12156863, 0.2       , 0.36862746],\n",
       "         [0.14901961, 0.21568628, 0.35686275],\n",
       "         [0.12156863, 0.18039216, 0.31764707],\n",
       "         ...,\n",
       "         [0.12941177, 0.25882354, 0.36078432],\n",
       "         [0.16078432, 0.26274511, 0.39215687],\n",
       "         [0.15686275, 0.27450982, 0.3882353 ]],\n",
       "\n",
       "        [[0.16862746, 0.23921569, 0.38431373],\n",
       "         [0.16862746, 0.23137255, 0.39215687],\n",
       "         [0.2       , 0.25098041, 0.41960785],\n",
       "         ...,\n",
       "         [0.17254902, 0.29411766, 0.40784314],\n",
       "         [0.22352941, 0.32156864, 0.4627451 ],\n",
       "         [0.16862746, 0.27450982, 0.40392157]],\n",
       "\n",
       "        [[0.20392157, 0.30588236, 0.45490196],\n",
       "         [0.19215687, 0.29019609, 0.48235294],\n",
       "         [0.21176471, 0.30588236, 0.48235294],\n",
       "         ...,\n",
       "         [0.18431373, 0.32156864, 0.43529412],\n",
       "         [0.12941177, 0.23921569, 0.33333334],\n",
       "         [0.12156863, 0.22352941, 0.31764707]]],\n",
       "\n",
       "\n",
       "       [[[0.8643503 , 0.85179559, 0.78802201],\n",
       "         [0.9748177 , 0.97420542, 0.98805758],\n",
       "         [0.9748177 , 0.97420542, 1.        ],\n",
       "         ...,\n",
       "         [0.28215722, 0.27557372, 0.30435391],\n",
       "         [0.27618601, 0.26661691, 0.2983827 ],\n",
       "         [0.27917161, 0.26960251, 0.2983827 ]],\n",
       "\n",
       "        [[0.84643666, 0.83686756, 0.80295003],\n",
       "         [0.9748177 , 0.97420542, 0.99402879],\n",
       "         [0.9748177 , 0.97420542, 1.        ],\n",
       "         ...,\n",
       "         [0.2732004 , 0.26661691, 0.2983827 ],\n",
       "         [0.2732004 , 0.26661691, 0.29539709],\n",
       "         [0.28215722, 0.26661691, 0.29539709]],\n",
       "\n",
       "        [[0.83150863, 0.82193954, 0.80295003],\n",
       "         [0.9748177 , 0.97420542, 1.        ],\n",
       "         [0.9748177 , 0.97420542, 1.        ],\n",
       "         ...,\n",
       "         [0.2732004 , 0.26661691, 0.2983827 ],\n",
       "         [0.2732004 , 0.26661691, 0.29539709],\n",
       "         [0.27917161, 0.26661691, 0.29241149]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.27917161, 0.27258812, 0.30733952],\n",
       "         [0.27917161, 0.26960251, 0.30733952],\n",
       "         [0.27917161, 0.27258812, 0.30733952],\n",
       "         ...,\n",
       "         [0.31798448, 0.32334341, 0.36406602],\n",
       "         [0.31798448, 0.32035781, 0.37003723],\n",
       "         [0.32395569, 0.32334341, 0.37600844]],\n",
       "\n",
       "        [[0.29111403, 0.28154493, 0.31928194],\n",
       "         [0.29111403, 0.28154493, 0.32226754],\n",
       "         [0.28812843, 0.27557372, 0.31629633],\n",
       "         ...,\n",
       "         [0.35082614, 0.35917068, 0.41482132],\n",
       "         [0.34784054, 0.36215628, 0.42676374],\n",
       "         [0.35082614, 0.36514189, 0.44169177]],\n",
       "\n",
       "        [[0.32395569, 0.30542978, 0.34316678],\n",
       "         [0.32097009, 0.30542978, 0.34316678],\n",
       "         [0.32097009, 0.29945857, 0.33420997],\n",
       "         ...,\n",
       "         [0.45532234, 0.47560929, 0.5700728 ],\n",
       "         [0.50607763, 0.53830701, 0.59097204],\n",
       "         [0.58967459, 0.62787518, 0.69248263]]],\n",
       "\n",
       "\n",
       "       [[[0.42352942, 0.4509804 , 0.34117648],\n",
       "         [0.66274512, 0.70588237, 0.60392159],\n",
       "         [0.52941179, 0.56078434, 0.46666667],\n",
       "         ...,\n",
       "         [0.16862746, 0.18039216, 0.19215687],\n",
       "         [0.18039216, 0.19607843, 0.21568628],\n",
       "         [0.17647059, 0.19215687, 0.21960784]],\n",
       "\n",
       "        [[0.36862746, 0.35686275, 0.27843139],\n",
       "         [0.68627453, 0.65490198, 0.57647061],\n",
       "         [0.56078434, 0.57254905, 0.50588238],\n",
       "         ...,\n",
       "         [0.16470589, 0.17647059, 0.18431373],\n",
       "         [0.16862746, 0.18431373, 0.2       ],\n",
       "         [0.16470589, 0.18431373, 0.20784314]],\n",
       "\n",
       "        [[0.38431373, 0.3882353 , 0.33725491],\n",
       "         [0.59607846, 0.59215689, 0.5411765 ],\n",
       "         [0.51372552, 0.51372552, 0.46666667],\n",
       "         ...,\n",
       "         [0.15686275, 0.17254902, 0.18039216],\n",
       "         [0.15686275, 0.17647059, 0.19215687],\n",
       "         [0.16470589, 0.18431373, 0.20784314]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.09803922, 0.10588235, 0.11764706],\n",
       "         [0.10196079, 0.10980392, 0.11372549],\n",
       "         [0.10196079, 0.11372549, 0.11372549],\n",
       "         ...,\n",
       "         [0.16470589, 0.16862746, 0.18431373],\n",
       "         [0.16470589, 0.17254902, 0.18431373],\n",
       "         [0.16862746, 0.17647059, 0.1882353 ]],\n",
       "\n",
       "        [[0.09803922, 0.10980392, 0.11764706],\n",
       "         [0.10196079, 0.11372549, 0.11764706],\n",
       "         [0.10588235, 0.11764706, 0.11764706],\n",
       "         ...,\n",
       "         [0.16470589, 0.16862746, 0.18039216],\n",
       "         [0.16862746, 0.17647059, 0.19215687],\n",
       "         [0.15686275, 0.16862746, 0.1882353 ]],\n",
       "\n",
       "        [[0.10196079, 0.11372549, 0.11764706],\n",
       "         [0.10588235, 0.11764706, 0.12156863],\n",
       "         [0.10588235, 0.11372549, 0.11764706],\n",
       "         ...,\n",
       "         [0.16470589, 0.17254902, 0.18431373],\n",
       "         [0.17254902, 0.18039216, 0.2       ],\n",
       "         [0.16862746, 0.18039216, 0.21176471]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.35294119, 0.27058825, 0.25882354],\n",
       "         [0.11764706, 0.1254902 , 0.13333334],\n",
       "         [0.17647059, 0.15686275, 0.13725491],\n",
       "         ...,\n",
       "         [0.05882353, 0.07058824, 0.06666667],\n",
       "         [0.05882353, 0.07058824, 0.06666667],\n",
       "         [0.07058824, 0.08235294, 0.07843138]],\n",
       "\n",
       "        [[0.32549021, 0.32156864, 0.28627452],\n",
       "         [0.14901961, 0.14901961, 0.16078432],\n",
       "         [0.16862746, 0.14509805, 0.14509805],\n",
       "         ...,\n",
       "         [0.05882353, 0.07058824, 0.0627451 ],\n",
       "         [0.05882353, 0.07450981, 0.06666667],\n",
       "         [0.07843138, 0.09803922, 0.09411765]],\n",
       "\n",
       "        [[0.68627453, 0.66274512, 0.55686277],\n",
       "         [0.26666668, 0.25882354, 0.27843139],\n",
       "         [0.1254902 , 0.12156863, 0.10980392],\n",
       "         ...,\n",
       "         [0.05882353, 0.07058824, 0.06666667],\n",
       "         [0.0627451 , 0.07450981, 0.07450981],\n",
       "         [0.10196079, 0.10980392, 0.10196079]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.13725491, 0.20392157, 0.21176471],\n",
       "         [0.17254902, 0.21960784, 0.21176471],\n",
       "         [0.22745098, 0.24313726, 0.20784314],\n",
       "         ...,\n",
       "         [0.49019608, 0.43137255, 0.38039216],\n",
       "         [0.48627451, 0.42352942, 0.37254903],\n",
       "         [0.4627451 , 0.39607844, 0.34509805]],\n",
       "\n",
       "        [[0.20784314, 0.24313726, 0.23921569],\n",
       "         [0.29019609, 0.28627452, 0.23529412],\n",
       "         [0.48235294, 0.42745098, 0.33333334],\n",
       "         ...,\n",
       "         [0.4509804 , 0.40784314, 0.36862746],\n",
       "         [0.45882353, 0.40784314, 0.36862746],\n",
       "         [0.4509804 , 0.39215687, 0.35294119]],\n",
       "\n",
       "        [[0.31764707, 0.3019608 , 0.23137255],\n",
       "         [0.50980395, 0.44705883, 0.34509805],\n",
       "         [0.61176473, 0.52941179, 0.43921569],\n",
       "         ...,\n",
       "         [0.32941177, 0.27843139, 0.24313726],\n",
       "         [0.34117648, 0.29019609, 0.27058825],\n",
       "         [0.34509805, 0.29019609, 0.27058825]]],\n",
       "\n",
       "\n",
       "       [[[0.21176471, 0.21568628, 0.23137255],\n",
       "         [0.19607843, 0.20392157, 0.20784314],\n",
       "         [0.1882353 , 0.20392157, 0.20392157],\n",
       "         ...,\n",
       "         [0.25490198, 0.28627452, 0.3137255 ],\n",
       "         [0.19607843, 0.23137255, 0.24313726],\n",
       "         [0.24313726, 0.29019609, 0.3137255 ]],\n",
       "\n",
       "        [[0.2       , 0.20784314, 0.21176471],\n",
       "         [0.18431373, 0.19607843, 0.19607843],\n",
       "         [0.18039216, 0.19215687, 0.2       ],\n",
       "         ...,\n",
       "         [0.25098041, 0.29019609, 0.30980393],\n",
       "         [0.2       , 0.23529412, 0.23529412],\n",
       "         [0.2       , 0.23921569, 0.24705882]],\n",
       "\n",
       "        [[0.2       , 0.21568628, 0.21960784],\n",
       "         [0.2       , 0.20784314, 0.21176471],\n",
       "         [0.19607843, 0.2       , 0.20784314],\n",
       "         ...,\n",
       "         [0.26274511, 0.32549021, 0.34901962],\n",
       "         [0.21960784, 0.26666668, 0.27450982],\n",
       "         [0.21176471, 0.25098041, 0.26274511]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.23921569, 0.27450982, 0.3137255 ],\n",
       "         [0.19607843, 0.23137255, 0.25490198],\n",
       "         [0.19215687, 0.21568628, 0.23137255],\n",
       "         ...,\n",
       "         [0.18431373, 0.20392157, 0.20392157],\n",
       "         [0.1882353 , 0.20392157, 0.20392157],\n",
       "         [0.18039216, 0.21176471, 0.21568628]],\n",
       "\n",
       "        [[0.21960784, 0.28235295, 0.32156864],\n",
       "         [0.20784314, 0.25098041, 0.27843139],\n",
       "         [0.20392157, 0.22745098, 0.24313726],\n",
       "         ...,\n",
       "         [0.18039216, 0.19607843, 0.19607843],\n",
       "         [0.19607843, 0.21176471, 0.21176471],\n",
       "         [0.1882353 , 0.21176471, 0.21176471]],\n",
       "\n",
       "        [[0.22352941, 0.28627452, 0.32549021],\n",
       "         [0.23529412, 0.28235295, 0.30588236],\n",
       "         [0.22352941, 0.24313726, 0.25882354],\n",
       "         ...,\n",
       "         [0.18039216, 0.19215687, 0.19607843],\n",
       "         [0.1882353 , 0.2       , 0.19607843],\n",
       "         [0.1882353 , 0.21176471, 0.21176471]]],\n",
       "\n",
       "\n",
       "       [[[0.47581653, 0.54092401, 0.68626222],\n",
       "         [0.48721183, 0.54852087, 0.70145594],\n",
       "         [0.49860712, 0.5637146 , 0.72804496],\n",
       "         ...,\n",
       "         [0.98860471, 0.93975926, 0.98253983],\n",
       "         [1.        , 0.96254985, 0.99393512],\n",
       "         [0.98480628, 0.95875141, 0.99013669]],\n",
       "\n",
       "        [[0.4720181 , 0.54092401, 0.68626222],\n",
       "         [0.48721183, 0.55991617, 0.7090528 ],\n",
       "         [0.48721183, 0.5637146 , 0.71664967],\n",
       "         ...,\n",
       "         [0.97341098, 0.92836397, 0.99013669],\n",
       "         [0.98860471, 0.95115455, 0.99393512],\n",
       "         [0.97341098, 0.94735612, 0.99013669]],\n",
       "\n",
       "        [[0.49860712, 0.5637146 , 0.7090528 ],\n",
       "         [0.50620398, 0.56751303, 0.71664967],\n",
       "         [0.47961496, 0.54092401, 0.69006065],\n",
       "         ...,\n",
       "         [0.90503923, 0.88658123, 0.95595081],\n",
       "         [0.93542667, 0.91696867, 0.97114454],\n",
       "         [0.95441883, 0.9321624 , 0.99013669]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.44163065, 0.45735853, 0.55711557],\n",
       "         [0.4226385 , 0.44216481, 0.54572027],\n",
       "         [0.4226385 , 0.44216481, 0.5495187 ],\n",
       "         ...,\n",
       "         [0.43403379, 0.44596324, 0.54192184],\n",
       "         [0.40744478, 0.41937422, 0.46975166],\n",
       "         [0.36566204, 0.37379305, 0.44696107]],\n",
       "\n",
       "        [[0.43403379, 0.4535601 , 0.55331714],\n",
       "         [0.41504164, 0.43456795, 0.53812341],\n",
       "         [0.40744478, 0.43076952, 0.53812341],\n",
       "         ...,\n",
       "         [0.47581653, 0.49914127, 0.57990615],\n",
       "         [0.44542909, 0.46115696, 0.50393753],\n",
       "         [0.39225105, 0.39658364, 0.46215479]],\n",
       "\n",
       "        [[0.43023536, 0.44216481, 0.54192184],\n",
       "         [0.41124321, 0.42317265, 0.52672812],\n",
       "         [0.40744478, 0.42697109, 0.53432498],\n",
       "         ...,\n",
       "         [0.44922752, 0.46495539, 0.53432498],\n",
       "         [0.45302595, 0.46115696, 0.5001391 ],\n",
       "         [0.41884007, 0.41557579, 0.47355009]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (27446, 32, 32, 3)\n",
      "X_valid.shape (11763, 32, 32, 3)\n",
      "y_train.shape (27446,)\n",
      "y_valid.shape (11763,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(bd_training_data, bd_training_label, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "X_train = X_train\n",
    "X_val = X_val\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_valid.shape\", X_val.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"y_valid.shape\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27446, 43)\n",
      "(11763, 43)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
    "y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Dense(43, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 1\n",
    "\n",
    "opt = tf.keras.optimizers.legacy.Adam(lr=lr, decay=lr / (epochs * 0.5))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 [==============================] - 83s 94ms/step - loss: 1.0729 - accuracy: 0.7051 - val_loss: 0.0927 - val_accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "history2 = model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('32_filter_test_data.npy',allow_pickle=True)\n",
    "test_labels = np.load('32_filter_test_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[[0.6784314 , 0.5411765 , 0.4509804 ],\n",
       "               [0.6745098 , 0.5411765 , 0.45490196],\n",
       "               [0.6627451 , 0.5372549 , 0.45490196],\n",
       "               ...,\n",
       "               [0.5294118 , 0.43137255, 0.3372549 ],\n",
       "               [0.49411765, 0.39607844, 0.3137255 ],\n",
       "               [0.4117647 , 0.32156864, 0.24705882]],\n",
       "\n",
       "              [[0.69803923, 0.56078434, 0.4627451 ],\n",
       "               [0.69411767, 0.54901963, 0.45490196],\n",
       "               [0.68235296, 0.5411765 , 0.4509804 ],\n",
       "               ...,\n",
       "               [0.67058825, 0.5568628 , 0.47058824],\n",
       "               [0.654902  , 0.54509807, 0.46666667],\n",
       "               [0.6509804 , 0.53333336, 0.45882353]],\n",
       "\n",
       "              [[0.69411767, 0.56078434, 0.45490196],\n",
       "               [0.68235296, 0.54509807, 0.44313726],\n",
       "               [0.68235296, 0.54901963, 0.4509804 ],\n",
       "               ...,\n",
       "               [0.6784314 , 0.5529412 , 0.47058824],\n",
       "               [0.6627451 , 0.54509807, 0.46666667],\n",
       "               [0.67058825, 0.54509807, 0.47058824]],\n",
       "\n",
       "              ...,\n",
       "\n",
       "              [[0.654902  , 0.53333336, 0.45490196],\n",
       "               [0.64705884, 0.53333336, 0.45490196],\n",
       "               [0.65882355, 0.5254902 , 0.44705883],\n",
       "               ...,\n",
       "               [0.64705884, 0.53333336, 0.45882353],\n",
       "               [0.64705884, 0.5411765 , 0.45490196],\n",
       "               [0.65882355, 0.54901963, 0.44705883]],\n",
       "\n",
       "              [[0.654902  , 0.5294118 , 0.44705883],\n",
       "               [0.64705884, 0.5294118 , 0.44705883],\n",
       "               [0.64705884, 0.52156866, 0.43529412],\n",
       "               ...,\n",
       "               [0.6509804 , 0.5372549 , 0.45882353],\n",
       "               [0.65882355, 0.54509807, 0.4509804 ],\n",
       "               [0.6666667 , 0.54901963, 0.43529412]],\n",
       "\n",
       "              [[0.65882355, 0.5294118 , 0.4392157 ],\n",
       "               [0.64705884, 0.5254902 , 0.43137255],\n",
       "               [0.64705884, 0.5294118 , 0.43137255],\n",
       "               ...,\n",
       "               [0.65882355, 0.54509807, 0.4627451 ],\n",
       "               [0.6666667 , 0.54509807, 0.45490196],\n",
       "               [0.6745098 , 0.54901963, 0.4509804 ]]], dtype=float32),\n",
       "       array([[[0.23921569, 0.27058825, 0.21568628],\n",
       "               [0.25490198, 0.32156864, 0.32156864],\n",
       "               [0.23921569, 0.30588236, 0.35686275],\n",
       "               ...,\n",
       "               [0.2627451 , 0.24705882, 0.27450982],\n",
       "               [0.2627451 , 0.25882354, 0.25882354],\n",
       "               [0.27058825, 0.27058825, 0.28627452]],\n",
       "\n",
       "              [[0.21960784, 0.25490198, 0.20784314],\n",
       "               [0.25490198, 0.32941177, 0.3372549 ],\n",
       "               [0.23921569, 0.30980393, 0.3764706 ],\n",
       "               ...,\n",
       "               [0.2627451 , 0.25490198, 0.30980393],\n",
       "               [0.27058825, 0.27058825, 0.33333334],\n",
       "               [0.26666668, 0.27058825, 0.3137255 ]],\n",
       "\n",
       "              [[0.21960784, 0.25490198, 0.21176471],\n",
       "               [0.27058825, 0.34117648, 0.36078432],\n",
       "               [0.24313726, 0.3137255 , 0.39607844],\n",
       "               ...,\n",
       "               [0.28627452, 0.2784314 , 0.3647059 ],\n",
       "               [0.27450982, 0.27058825, 0.4       ],\n",
       "               [0.26666668, 0.26666668, 0.33333334]],\n",
       "\n",
       "              ...,\n",
       "\n",
       "              [[0.16078432, 0.16862746, 0.17254902],\n",
       "               [0.23921569, 0.2627451 , 0.29411766],\n",
       "               [0.23137255, 0.25882354, 0.32156864],\n",
       "               ...,\n",
       "               [0.2509804 , 0.2509804 , 0.25490198],\n",
       "               [0.25490198, 0.25490198, 0.27058825],\n",
       "               [0.2627451 , 0.2627451 , 0.28627452]],\n",
       "\n",
       "              [[0.16862746, 0.16862746, 0.18039216],\n",
       "               [0.24705882, 0.25882354, 0.29411766],\n",
       "               [0.24313726, 0.2627451 , 0.3254902 ],\n",
       "               ...,\n",
       "               [0.25490198, 0.24705882, 0.25882354],\n",
       "               [0.26666668, 0.26666668, 0.28627452],\n",
       "               [0.2627451 , 0.26666668, 0.28627452]],\n",
       "\n",
       "              [[0.16078432, 0.16078432, 0.18039216],\n",
       "               [0.24313726, 0.25490198, 0.29411766],\n",
       "               [0.23529412, 0.25882354, 0.32156864],\n",
       "               ...,\n",
       "               [0.27450982, 0.25490198, 0.27450982],\n",
       "               [0.28235295, 0.27450982, 0.3019608 ],\n",
       "               [0.2784314 , 0.2784314 , 0.29411766]]], dtype=float32),\n",
       "       array([[[0.14117648, 0.14901961, 0.19607843],\n",
       "               [0.14901961, 0.15294118, 0.19607843],\n",
       "               [0.14509805, 0.14901961, 0.19215687],\n",
       "               ...,\n",
       "               [0.1882353 , 0.1764706 , 0.21176471],\n",
       "               [0.1882353 , 0.1764706 , 0.21568628],\n",
       "               [0.19215687, 0.18039216, 0.21568628]],\n",
       "\n",
       "              [[0.16078432, 0.17254902, 0.22352941],\n",
       "               [0.15294118, 0.16470589, 0.21568628],\n",
       "               [0.14901961, 0.16078432, 0.21176471],\n",
       "               ...,\n",
       "               [0.1882353 , 0.17254902, 0.20784314],\n",
       "               [0.18039216, 0.17254902, 0.20784314],\n",
       "               [0.18039216, 0.1764706 , 0.21176471]],\n",
       "\n",
       "              [[0.16470589, 0.1764706 , 0.23137255],\n",
       "               [0.16862746, 0.18039216, 0.23529412],\n",
       "               [0.16078432, 0.17254902, 0.23137255],\n",
       "               ...,\n",
       "               [0.1764706 , 0.17254902, 0.21176471],\n",
       "               [0.1764706 , 0.1764706 , 0.21176471],\n",
       "               [0.1764706 , 0.18039216, 0.21960784]],\n",
       "\n",
       "              ...,\n",
       "\n",
       "              [[0.10980392, 0.10588235, 0.11764706],\n",
       "               [0.1254902 , 0.11764706, 0.13333334],\n",
       "               [0.13725491, 0.12941177, 0.14901961],\n",
       "               ...,\n",
       "               [0.14117648, 0.14901961, 0.15686275],\n",
       "               [0.17254902, 0.1764706 , 0.18431373],\n",
       "               [0.1764706 , 0.1764706 , 0.18431373]],\n",
       "\n",
       "              [[0.1254902 , 0.12156863, 0.13725491],\n",
       "               [0.14117648, 0.13725491, 0.16078432],\n",
       "               [0.11764706, 0.11372549, 0.14509805],\n",
       "               ...,\n",
       "               [0.16078432, 0.16078432, 0.16470589],\n",
       "               [0.16862746, 0.17254902, 0.18039216],\n",
       "               [0.18039216, 0.18431373, 0.19215687]],\n",
       "\n",
       "              [[0.10980392, 0.10588235, 0.11372549],\n",
       "               [0.10980392, 0.10588235, 0.12156863],\n",
       "               [0.10196079, 0.10196079, 0.12156863],\n",
       "               ...,\n",
       "               [0.17254902, 0.16862746, 0.17254902],\n",
       "               [0.17254902, 0.1764706 , 0.18039216],\n",
       "               [0.16862746, 0.18039216, 0.18431373]]], dtype=float32),\n",
       "       ..., array([[[0.47946007, 0.37824845, 0.34272221],\n",
       "                    [0.4651987 , 0.36398708, 0.33559152],\n",
       "                    [0.4651987 , 0.36398708, 0.34272221],\n",
       "                    ...,\n",
       "                    [0.47232939, 0.37824845, 0.35698358],\n",
       "                    [0.47946007, 0.37824845, 0.35698358],\n",
       "                    [0.47946007, 0.37824845, 0.35698358]],\n",
       "\n",
       "                   [[0.47232939, 0.37111776, 0.34985289],\n",
       "                    [0.47946007, 0.37111776, 0.34985289],\n",
       "                    [0.47232939, 0.37111776, 0.35698358],\n",
       "                    ...,\n",
       "                    [0.47946007, 0.37824845, 0.35698358],\n",
       "                    [0.48659075, 0.37824845, 0.36411426],\n",
       "                    [0.49372144, 0.38537913, 0.37124494]],\n",
       "\n",
       "                   [[0.4651987 , 0.37111776, 0.35698358],\n",
       "                    [0.4651987 , 0.36398708, 0.34985289],\n",
       "                    [0.45093733, 0.35685639, 0.34272221],\n",
       "                    ...,\n",
       "                    [0.47232939, 0.37824845, 0.35698358],\n",
       "                    [0.47232939, 0.37824845, 0.36411426],\n",
       "                    [0.47232939, 0.37111776, 0.36411426]],\n",
       "\n",
       "                   ...,\n",
       "\n",
       "                   [[0.38676118, 0.30694161, 0.28567674],\n",
       "                    [0.38676118, 0.29981092, 0.27854605],\n",
       "                    [0.38676118, 0.29981092, 0.27141537],\n",
       "                    ...,\n",
       "                    [0.44380665, 0.33546434, 0.30706879],\n",
       "                    [0.47232939, 0.34972571, 0.32133016],\n",
       "                    [0.45093733, 0.33546434, 0.30706879]],\n",
       "\n",
       "                   [[0.39389186, 0.30694161, 0.28567674],\n",
       "                    [0.38676118, 0.29981092, 0.27854605],\n",
       "                    [0.38676118, 0.29981092, 0.27141537],\n",
       "                    ...,\n",
       "                    [0.45093733, 0.33546434, 0.30706879],\n",
       "                    [0.4651987 , 0.34259503, 0.31419947],\n",
       "                    [0.4651987 , 0.34259503, 0.30706879]],\n",
       "\n",
       "                   [[0.38676118, 0.29981092, 0.27854605],\n",
       "                    [0.38676118, 0.29981092, 0.27854605],\n",
       "                    [0.38676118, 0.29981092, 0.27141537],\n",
       "                    ...,\n",
       "                    [0.45093733, 0.33546434, 0.2999381 ],\n",
       "                    [0.4651987 , 0.34259503, 0.30706879],\n",
       "                    [0.45806802, 0.34259503, 0.2999381 ]]]),\n",
       "       array([[[0.79892662, 0.6500847 , 0.55381303],\n",
       "               [0.81382095, 0.62029605, 0.55381303],\n",
       "               [0.7840323 , 0.63519037, 0.598496  ],\n",
       "               ...,\n",
       "               [0.33720256, 0.27772659, 0.30060951],\n",
       "               [0.33720256, 0.27027943, 0.27826803],\n",
       "               [0.33720256, 0.27027943, 0.27826803]],\n",
       "\n",
       "              [[0.79147946, 0.64263754, 0.56126019],\n",
       "               [0.70211351, 0.56816591, 0.53147154],\n",
       "               [0.61274757, 0.50114145, 0.50168289],\n",
       "               ...,\n",
       "               [0.33720256, 0.27772659, 0.30060951],\n",
       "               [0.3297554 , 0.27027943, 0.27826803],\n",
       "               [0.33720256, 0.27027943, 0.27826803]],\n",
       "\n",
       "              [[0.90318689, 0.73945065, 0.67296762],\n",
       "               [0.8808454 , 0.72455632, 0.7176506 ],\n",
       "               [0.80637378, 0.6500847 , 0.69530911],\n",
       "               ...,\n",
       "               [0.29996675, 0.27772659, 0.30060951],\n",
       "               [0.31486108, 0.27027943, 0.28571519],\n",
       "               [0.3297554 , 0.27027943, 0.28571519]],\n",
       "\n",
       "              ...,\n",
       "\n",
       "              [[0.35954405, 0.29262091, 0.30060951],\n",
       "               [0.36699121, 0.30006808, 0.30805668],\n",
       "               [0.35209689, 0.29262091, 0.30060951],\n",
       "               ...,\n",
       "               [0.54572311, 0.45645848, 0.4421056 ],\n",
       "               [0.51593446, 0.47135281, 0.44955276],\n",
       "               [0.40422702, 0.38943402, 0.39742262]],\n",
       "\n",
       "              [[0.35209689, 0.28517375, 0.29316235],\n",
       "               [0.35209689, 0.28517375, 0.29316235],\n",
       "               [0.35209689, 0.29262091, 0.30060951],\n",
       "               ...,\n",
       "               [0.54572311, 0.47135281, 0.45699992],\n",
       "               [0.5084873 , 0.47135281, 0.46444708],\n",
       "               [0.38188554, 0.38198686, 0.39742262]],\n",
       "\n",
       "              [[0.35209689, 0.28517375, 0.29316235],\n",
       "               [0.37443838, 0.30006808, 0.30805668],\n",
       "               [0.34464973, 0.28517375, 0.29316235],\n",
       "               ...,\n",
       "               [0.56061743, 0.48624713, 0.47189425],\n",
       "               [0.52338162, 0.47879997, 0.47934141],\n",
       "               [0.38188554, 0.38198686, 0.40486979]]]),\n",
       "       array([[[0.37020082, 0.29813658, 0.33010325],\n",
       "               [0.37020082, 0.29813658, 0.33010325],\n",
       "               [0.35915171, 0.28708747, 0.33010325],\n",
       "               ...,\n",
       "               [0.39229904, 0.32023479, 0.36325058],\n",
       "               [0.39229904, 0.32023479, 0.36325058],\n",
       "               [0.40334815, 0.32023479, 0.36325058]],\n",
       "\n",
       "              [[0.38124993, 0.30918569, 0.35220147],\n",
       "               [0.35915171, 0.28708747, 0.31905414],\n",
       "               [0.35915171, 0.28708747, 0.31905414],\n",
       "               ...,\n",
       "               [0.38124993, 0.32023479, 0.36325058],\n",
       "               [0.39229904, 0.32023479, 0.36325058],\n",
       "               [0.40334815, 0.32023479, 0.36325058]],\n",
       "\n",
       "              [[0.34810261, 0.28708747, 0.34115236],\n",
       "               [0.34810261, 0.27603836, 0.31905414],\n",
       "               [0.35915171, 0.28708747, 0.31905414],\n",
       "               ...,\n",
       "               [0.38124993, 0.32023479, 0.36325058],\n",
       "               [0.39229904, 0.32023479, 0.36325058],\n",
       "               [0.40334815, 0.32023479, 0.36325058]],\n",
       "\n",
       "              ...,\n",
       "\n",
       "              [[0.37020082, 0.28708747, 0.34115236],\n",
       "               [0.35915171, 0.28708747, 0.33010325],\n",
       "               [0.37020082, 0.29813658, 0.34115236],\n",
       "               ...,\n",
       "               [0.37020082, 0.29813658, 0.34115236],\n",
       "               [0.35915171, 0.28708747, 0.33010325],\n",
       "               [0.38124993, 0.30918569, 0.35220147]],\n",
       "\n",
       "              [[0.38124993, 0.29813658, 0.34115236],\n",
       "               [0.38124993, 0.29813658, 0.34115236],\n",
       "               [0.38124993, 0.29813658, 0.34115236],\n",
       "               ...,\n",
       "               [0.35915171, 0.28708747, 0.31905414],\n",
       "               [0.34810261, 0.28708747, 0.31905414],\n",
       "               [0.37020082, 0.30918569, 0.35220147]],\n",
       "\n",
       "              [[0.37020082, 0.29813658, 0.33010325],\n",
       "               [0.35915171, 0.28708747, 0.33010325],\n",
       "               [0.35915171, 0.28708747, 0.34115236],\n",
       "               ...,\n",
       "               [0.37020082, 0.29813658, 0.33010325],\n",
       "               [0.35915171, 0.29813658, 0.31905414],\n",
       "               [0.37020082, 0.30918569, 0.34115236]]])], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m X_test \u001b[38;5;241m=\u001b[39m test_data\n\u001b[1;32m----> 4\u001b[0m pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Accuracy with the test data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Data accuracy: \u001b[39m\u001b[38;5;124m'\u001b[39m,accuracy_score(test_labels, pred)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = test_data\n",
    "\n",
    "\n",
    "pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "#Accuracy with the test data\n",
    "print('Test Data accuracy: ',accuracy_score(test_labels, pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(test_labels, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
