{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No filter dataset through the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(42)\n",
    "\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data2 = np.load('30_original_train_data.npy')\n",
    "training_label2 = np.load('30_original_train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 15, 13, ..., 39,  1, 10])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_label = np.load('john_label_vec.npy')\n",
    "john_data = np.load('john_data_vec.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CATEGORIES = 43\n",
    "IMG_HEIGHT =30\n",
    "IMG_WIDTH=30\n",
    "channels =3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 30, 30, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 42,  59, 106],\n",
       "         [ 39,  54,  95],\n",
       "         [ 33,  50,  74],\n",
       "         ...,\n",
       "         [ 41,  82, 139],\n",
       "         [ 47,  82, 131],\n",
       "         [ 65, 109, 170]],\n",
       "\n",
       "        [[ 47,  66, 105],\n",
       "         [ 39,  58,  91],\n",
       "         [ 29,  50,  88],\n",
       "         ...,\n",
       "         [ 25,  59,  95],\n",
       "         [ 18,  48,  61],\n",
       "         [ 27,  65,  79]],\n",
       "\n",
       "        [[ 49,  72, 116],\n",
       "         [ 37,  65,  98],\n",
       "         [ 28,  58, 101],\n",
       "         ...,\n",
       "         [ 31,  62,  93],\n",
       "         [ 24,  54,  74],\n",
       "         [ 21,  55,  74]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 30,  51,  94],\n",
       "         [ 36,  55,  90],\n",
       "         [ 30,  48,  82],\n",
       "         ...,\n",
       "         [ 33,  68,  94],\n",
       "         [ 38,  66,  99],\n",
       "         [ 39,  70,  99]],\n",
       "\n",
       "        [[ 42,  60,  97],\n",
       "         [ 43,  58, 100],\n",
       "         [ 50,  63, 105],\n",
       "         ...,\n",
       "         [ 41,  74, 104],\n",
       "         [ 55,  80, 116],\n",
       "         [ 44,  71, 104]],\n",
       "\n",
       "        [[ 52,  77, 115],\n",
       "         [ 49,  73, 122],\n",
       "         [ 54,  78, 123],\n",
       "         ...,\n",
       "         [ 46,  83, 113],\n",
       "         [ 36,  64,  89],\n",
       "         [ 32,  58,  82]]],\n",
       "\n",
       "\n",
       "       [[[220, 216, 187],\n",
       "         [255, 255, 252],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [ 23,  21,  22],\n",
       "         [ 21,  18,  20],\n",
       "         [ 22,  19,  20]],\n",
       "\n",
       "        [[213, 211, 192],\n",
       "         [255, 255, 254],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [ 20,  18,  20],\n",
       "         [ 20,  18,  19],\n",
       "         [ 23,  18,  19]],\n",
       "\n",
       "        [[210, 207, 192],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [ 20,  18,  20],\n",
       "         [ 20,  18,  19],\n",
       "         [ 22,  18,  19]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 22,  20,  23],\n",
       "         [ 22,  19,  22],\n",
       "         [ 22,  20,  23],\n",
       "         ...,\n",
       "         [ 34,  36,  39],\n",
       "         [ 33,  34,  41],\n",
       "         [ 34,  34,  42]],\n",
       "\n",
       "        [[ 25,  23,  27],\n",
       "         [ 25,  23,  27],\n",
       "         [ 25,  21,  26],\n",
       "         ...,\n",
       "         [ 46,  47,  57],\n",
       "         [ 43,  48,  61],\n",
       "         [ 44,  49,  65]],\n",
       "\n",
       "        [[ 36,  31,  35],\n",
       "         [ 36,  31,  35],\n",
       "         [ 35,  29,  32],\n",
       "         ...,\n",
       "         [ 78,  84, 109],\n",
       "         [ 94, 104, 114],\n",
       "         [121, 134, 146]]],\n",
       "\n",
       "\n",
       "       [[[110, 118,  90],\n",
       "         [168, 178, 152],\n",
       "         [128, 136, 115],\n",
       "         ...,\n",
       "         [ 42,  45,  48],\n",
       "         [ 46,  50,  54],\n",
       "         [ 45,  49,  56]],\n",
       "\n",
       "        [[ 98,  95,  75],\n",
       "         [172, 164, 145],\n",
       "         [135, 139, 124],\n",
       "         ...,\n",
       "         [ 41,  44,  46],\n",
       "         [ 43,  47,  51],\n",
       "         [ 42,  47,  53]],\n",
       "\n",
       "        [[102, 104,  94],\n",
       "         [151, 152, 140],\n",
       "         [127, 126, 114],\n",
       "         ...,\n",
       "         [ 40,  44,  46],\n",
       "         [ 40,  45,  49],\n",
       "         [ 42,  47,  53]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 25,  27,  30],\n",
       "         [ 26,  28,  29],\n",
       "         [ 26,  29,  29],\n",
       "         ...,\n",
       "         [ 42,  43,  47],\n",
       "         [ 42,  44,  47],\n",
       "         [ 43,  45,  48]],\n",
       "\n",
       "        [[ 25,  28,  30],\n",
       "         [ 26,  29,  30],\n",
       "         [ 27,  30,  30],\n",
       "         ...,\n",
       "         [ 42,  43,  46],\n",
       "         [ 43,  45,  49],\n",
       "         [ 40,  43,  48]],\n",
       "\n",
       "        [[ 26,  29,  30],\n",
       "         [ 27,  30,  31],\n",
       "         [ 27,  29,  30],\n",
       "         ...,\n",
       "         [ 42,  44,  47],\n",
       "         [ 44,  46,  51],\n",
       "         [ 43,  46,  54]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 86,  67,  64],\n",
       "         [ 31,  32,  34],\n",
       "         [ 43,  39,  34],\n",
       "         ...,\n",
       "         [ 15,  18,  17],\n",
       "         [ 15,  18,  17],\n",
       "         [ 18,  21,  20]],\n",
       "\n",
       "        [[ 89,  88,  78],\n",
       "         [ 40,  39,  42],\n",
       "         [ 45,  40,  40],\n",
       "         ...,\n",
       "         [ 15,  18,  16],\n",
       "         [ 15,  19,  17],\n",
       "         [ 21,  25,  24]],\n",
       "\n",
       "        [[175, 166, 142],\n",
       "         [ 69,  66,  70],\n",
       "         [ 40,  39,  34],\n",
       "         ...,\n",
       "         [ 15,  18,  17],\n",
       "         [ 17,  19,  19],\n",
       "         [ 26,  28,  26]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 32,  48,  50],\n",
       "         [ 41,  52,  51],\n",
       "         [ 55,  60,  51],\n",
       "         ...,\n",
       "         [124, 108,  96],\n",
       "         [124, 107,  93],\n",
       "         [121, 102,  89]],\n",
       "\n",
       "        [[ 52,  61,  61],\n",
       "         [ 75,  74,  61],\n",
       "         [122, 109,  86],\n",
       "         ...,\n",
       "         [116, 104,  94],\n",
       "         [118, 105,  95],\n",
       "         [116, 100,  90]],\n",
       "\n",
       "        [[ 82,  78,  60],\n",
       "         [131, 115,  90],\n",
       "         [154, 133, 110],\n",
       "         ...,\n",
       "         [ 83,  71,  62],\n",
       "         [ 88,  75,  69],\n",
       "         [ 89,  75,  70]]],\n",
       "\n",
       "\n",
       "       [[[ 54,  55,  59],\n",
       "         [ 50,  52,  53],\n",
       "         [ 48,  53,  52],\n",
       "         ...,\n",
       "         [ 71,  78,  84],\n",
       "         [ 51,  60,  63],\n",
       "         [ 60,  72,  78]],\n",
       "\n",
       "        [[ 51,  53,  54],\n",
       "         [ 47,  50,  50],\n",
       "         [ 46,  49,  52],\n",
       "         ...,\n",
       "         [ 68,  79,  84],\n",
       "         [ 52,  62,  62],\n",
       "         [ 51,  61,  63]],\n",
       "\n",
       "        [[ 51,  55,  56],\n",
       "         [ 51,  53,  55],\n",
       "         [ 50,  52,  54],\n",
       "         ...,\n",
       "         [ 68,  86,  92],\n",
       "         [ 58,  71,  75],\n",
       "         [ 55,  65,  69]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 59,  68,  77],\n",
       "         [ 50,  58,  64],\n",
       "         [ 50,  56,  59],\n",
       "         ...,\n",
       "         [ 47,  52,  52],\n",
       "         [ 48,  53,  53],\n",
       "         [ 47,  56,  57]],\n",
       "\n",
       "        [[ 56,  72,  82],\n",
       "         [ 53,  62,  69],\n",
       "         [ 53,  58,  62],\n",
       "         ...,\n",
       "         [ 45,  50,  50],\n",
       "         [ 50,  54,  54],\n",
       "         [ 48,  54,  54]],\n",
       "\n",
       "        [[ 57,  73,  83],\n",
       "         [ 60,  71,  77],\n",
       "         [ 57,  61,  65],\n",
       "         ...,\n",
       "         [ 46,  49,  50],\n",
       "         [ 48,  51,  50],\n",
       "         [ 48,  54,  54]]],\n",
       "\n",
       "\n",
       "       [[[ 59,  76,  98],\n",
       "         [ 62,  78, 103],\n",
       "         [ 65,  82, 109],\n",
       "         ...,\n",
       "         [193, 180, 176],\n",
       "         [197, 187, 179],\n",
       "         [193, 186, 178]],\n",
       "\n",
       "        [[ 59,  77,  99],\n",
       "         [ 63,  81, 104],\n",
       "         [ 61,  80, 104],\n",
       "         ...,\n",
       "         [188, 176, 176],\n",
       "         [193, 183, 179],\n",
       "         [190, 183, 178]],\n",
       "\n",
       "        [[ 64,  81, 103],\n",
       "         [ 65,  81, 104],\n",
       "         [ 59,  75,  98],\n",
       "         ...,\n",
       "         [166, 162, 165],\n",
       "         [176, 172, 172],\n",
       "         [184, 178, 178]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 51,  55,  65],\n",
       "         [ 46,  51,  62],\n",
       "         [ 46,  51,  63],\n",
       "         ...,\n",
       "         [ 47,  49,  60],\n",
       "         [ 41,  44,  43],\n",
       "         [ 31,  34,  37]],\n",
       "\n",
       "        [[ 48,  53,  63],\n",
       "         [ 43,  48,  59],\n",
       "         [ 41,  47,  60],\n",
       "         ...,\n",
       "         [ 59,  64,  70],\n",
       "         [ 51,  55,  51],\n",
       "         [ 37,  38,  38]],\n",
       "\n",
       "        [[ 47,  50,  60],\n",
       "         [ 42,  45,  56],\n",
       "         [ 41,  47,  59],\n",
       "         ...,\n",
       "         [ 53,  58,  61],\n",
       "         [ 53,  55,  50],\n",
       "         [ 44,  44,  42]]]], dtype=uint8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 15, 13, ..., 39,  1, 10])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_label #not already one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2.shape (27446, 30, 30, 3)\n",
      "X_valid2.shape (11763, 30, 30, 3)\n",
      "y_train2.shape (27446,)\n",
      "y_valid2.shape (11763,)\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(john_data, john_label, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "X_train2 = X_train2/255\n",
    "X_val = X_val2/255\n",
    "\n",
    "print(\"X_train2.shape\", X_train2.shape)\n",
    "print(\"X_valid2.shape\", X_val2.shape)\n",
    "print(\"y_train2.shape\", y_train2.shape)\n",
    "print(\"y_valid2.shape\", y_val2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.07058824, 0.08235294, 0.09803922],\n",
       "         [0.07058824, 0.08235294, 0.09019608],\n",
       "         [0.06666667, 0.0745098 , 0.07843137],\n",
       "         ...,\n",
       "         [0.0627451 , 0.05490196, 0.07058824],\n",
       "         [0.0627451 , 0.05490196, 0.06666667],\n",
       "         [0.0627451 , 0.05490196, 0.06666667]],\n",
       "\n",
       "        [[0.07058824, 0.0745098 , 0.08627451],\n",
       "         [0.07058824, 0.0745098 , 0.08235294],\n",
       "         [0.07843137, 0.07843137, 0.08627451],\n",
       "         ...,\n",
       "         [0.0627451 , 0.05098039, 0.0627451 ],\n",
       "         [0.06666667, 0.05490196, 0.06666667],\n",
       "         [0.0745098 , 0.0627451 , 0.0745098 ]],\n",
       "\n",
       "        [[0.06666667, 0.07058824, 0.07843137],\n",
       "         [0.0627451 , 0.06666667, 0.0745098 ],\n",
       "         [0.07058824, 0.0745098 , 0.07843137],\n",
       "         ...,\n",
       "         [0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         [0.0627451 , 0.05882353, 0.06666667],\n",
       "         [0.0627451 , 0.05490196, 0.06666667]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.30980392, 0.24705882, 0.45098039],\n",
       "         [0.23137255, 0.27843137, 0.36078431],\n",
       "         [0.18039216, 0.24313725, 0.24705882],\n",
       "         ...,\n",
       "         [0.0627451 , 0.05490196, 0.0627451 ],\n",
       "         [0.06666667, 0.05490196, 0.0627451 ],\n",
       "         [0.06666667, 0.05490196, 0.0627451 ]],\n",
       "\n",
       "        [[0.25490196, 0.23529412, 0.35294118],\n",
       "         [0.30588235, 0.34509804, 0.39215686],\n",
       "         [0.29411765, 0.3372549 , 0.35294118],\n",
       "         ...,\n",
       "         [0.06666667, 0.05490196, 0.0627451 ],\n",
       "         [0.07058824, 0.05882353, 0.06666667],\n",
       "         [0.0627451 , 0.05490196, 0.06666667]],\n",
       "\n",
       "        [[0.16470588, 0.20784314, 0.2745098 ],\n",
       "         [0.16862745, 0.19607843, 0.22745098],\n",
       "         [0.18431373, 0.18039216, 0.20784314],\n",
       "         ...,\n",
       "         [0.07058824, 0.05882353, 0.06666667],\n",
       "         [0.06666667, 0.05490196, 0.0627451 ],\n",
       "         [0.05882353, 0.05490196, 0.0627451 ]]],\n",
       "\n",
       "\n",
       "       [[[0.68627451, 0.56862745, 0.49019608],\n",
       "         [0.67843137, 0.56078431, 0.47843137],\n",
       "         [0.68235294, 0.55686275, 0.47843137],\n",
       "         ...,\n",
       "         [0.56078431, 0.4627451 , 0.41960784],\n",
       "         [0.49019608, 0.40784314, 0.33333333],\n",
       "         [0.59215686, 0.47058824, 0.38039216]],\n",
       "\n",
       "        [[0.6745098 , 0.56078431, 0.49411765],\n",
       "         [0.67843137, 0.56078431, 0.49019608],\n",
       "         [0.67843137, 0.56078431, 0.49019608],\n",
       "         ...,\n",
       "         [0.59607843, 0.50196078, 0.43921569],\n",
       "         [0.49019608, 0.43529412, 0.37647059],\n",
       "         [0.54117647, 0.42352941, 0.35294118]],\n",
       "\n",
       "        [[0.68235294, 0.56078431, 0.49411765],\n",
       "         [0.67843137, 0.55294118, 0.49411765],\n",
       "         [0.6627451 , 0.54901961, 0.48235294],\n",
       "         ...,\n",
       "         [0.62745098, 0.51372549, 0.44313725],\n",
       "         [0.56862745, 0.49019608, 0.43529412],\n",
       "         [0.5254902 , 0.43137255, 0.38431373]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.12156863, 0.10196078, 0.09411765],\n",
       "         [0.13333333, 0.10980392, 0.10588235],\n",
       "         [0.1372549 , 0.11372549, 0.10588235],\n",
       "         ...,\n",
       "         [0.12941176, 0.11372549, 0.09803922],\n",
       "         [0.14901961, 0.12941176, 0.11372549],\n",
       "         [0.1372549 , 0.1254902 , 0.11372549]],\n",
       "\n",
       "        [[0.10980392, 0.09411765, 0.08627451],\n",
       "         [0.12156863, 0.09803922, 0.09019608],\n",
       "         [0.1372549 , 0.10588235, 0.09411765],\n",
       "         ...,\n",
       "         [0.21176471, 0.17647059, 0.14117647],\n",
       "         [0.21176471, 0.17647059, 0.14509804],\n",
       "         [0.2       , 0.16078431, 0.14901961]],\n",
       "\n",
       "        [[0.11372549, 0.09411765, 0.08627451],\n",
       "         [0.12156863, 0.09803922, 0.09019608],\n",
       "         [0.12941176, 0.09411765, 0.09019608],\n",
       "         ...,\n",
       "         [0.32941176, 0.2745098 , 0.21568627],\n",
       "         [0.3254902 , 0.2745098 , 0.22745098],\n",
       "         [0.32156863, 0.2627451 , 0.2627451 ]]],\n",
       "\n",
       "\n",
       "       [[[0.16078431, 0.18039216, 0.2       ],\n",
       "         [0.17254902, 0.19215686, 0.21176471],\n",
       "         [0.19607843, 0.21176471, 0.21960784],\n",
       "         ...,\n",
       "         [0.16862745, 0.20392157, 0.19607843],\n",
       "         [0.16078431, 0.19607843, 0.18823529],\n",
       "         [0.15686275, 0.18039216, 0.17647059]],\n",
       "\n",
       "        [[0.15686275, 0.18039216, 0.19607843],\n",
       "         [0.19215686, 0.21176471, 0.21176471],\n",
       "         [0.18823529, 0.21176471, 0.21960784],\n",
       "         ...,\n",
       "         [0.19215686, 0.23529412, 0.22352941],\n",
       "         [0.18039216, 0.21960784, 0.20784314],\n",
       "         [0.18039216, 0.20784314, 0.20392157]],\n",
       "\n",
       "        [[0.13333333, 0.14901961, 0.14117647],\n",
       "         [0.16078431, 0.18039216, 0.18039216],\n",
       "         [0.2       , 0.21960784, 0.22745098],\n",
       "         ...,\n",
       "         [0.19215686, 0.21960784, 0.21568627],\n",
       "         [0.17647059, 0.20784314, 0.2       ],\n",
       "         [0.16470588, 0.20392157, 0.19607843]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.11372549, 0.11764706, 0.11372549],\n",
       "         [0.11764706, 0.12156863, 0.11764706],\n",
       "         [0.11764706, 0.1254902 , 0.12156863],\n",
       "         ...,\n",
       "         [0.16470588, 0.17254902, 0.16862745],\n",
       "         [0.14509804, 0.14509804, 0.1372549 ],\n",
       "         [0.12156863, 0.11372549, 0.11372549]],\n",
       "\n",
       "        [[0.12941176, 0.1372549 , 0.13333333],\n",
       "         [0.12941176, 0.12941176, 0.12156863],\n",
       "         [0.12156863, 0.12941176, 0.1254902 ],\n",
       "         ...,\n",
       "         [0.15686275, 0.15686275, 0.15294118],\n",
       "         [0.14117647, 0.1372549 , 0.12941176],\n",
       "         [0.11764706, 0.10980392, 0.10980392]],\n",
       "\n",
       "        [[0.1372549 , 0.14117647, 0.13333333],\n",
       "         [0.1254902 , 0.1254902 , 0.12156863],\n",
       "         [0.12156863, 0.12941176, 0.1254902 ],\n",
       "         ...,\n",
       "         [0.1372549 , 0.14117647, 0.1372549 ],\n",
       "         [0.12941176, 0.1254902 , 0.12941176],\n",
       "         [0.12156863, 0.11372549, 0.11764706]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.05490196, 0.05098039, 0.05098039],\n",
       "         [0.07058824, 0.05098039, 0.05490196],\n",
       "         [0.07843137, 0.06666667, 0.07058824],\n",
       "         ...,\n",
       "         [0.05490196, 0.03921569, 0.04705882],\n",
       "         [0.05098039, 0.04313725, 0.03921569],\n",
       "         [0.05882353, 0.05098039, 0.05098039]],\n",
       "\n",
       "        [[0.05098039, 0.04313725, 0.04313725],\n",
       "         [0.0745098 , 0.05098039, 0.05490196],\n",
       "         [0.0745098 , 0.05882353, 0.0627451 ],\n",
       "         ...,\n",
       "         [0.05098039, 0.03921569, 0.03921569],\n",
       "         [0.05098039, 0.03529412, 0.03529412],\n",
       "         [0.05098039, 0.03529412, 0.03529412]],\n",
       "\n",
       "        [[0.05098039, 0.03921569, 0.03529412],\n",
       "         [0.07843137, 0.05490196, 0.04705882],\n",
       "         [0.0745098 , 0.05882353, 0.05882353],\n",
       "         ...,\n",
       "         [0.05490196, 0.04313725, 0.04705882],\n",
       "         [0.04705882, 0.03529412, 0.03921569],\n",
       "         [0.05098039, 0.03921569, 0.03921569]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.05882353, 0.04313725, 0.04313725],\n",
       "         [0.05098039, 0.03921569, 0.04313725],\n",
       "         [0.04313725, 0.03529412, 0.03921569],\n",
       "         ...,\n",
       "         [0.04705882, 0.03921569, 0.03921569],\n",
       "         [0.05490196, 0.03921569, 0.03921569],\n",
       "         [0.05882353, 0.04313725, 0.04705882]],\n",
       "\n",
       "        [[0.05490196, 0.04313725, 0.04313725],\n",
       "         [0.05098039, 0.03921569, 0.04313725],\n",
       "         [0.04705882, 0.03921569, 0.04313725],\n",
       "         ...,\n",
       "         [0.04705882, 0.03529412, 0.03921569],\n",
       "         [0.05098039, 0.03921569, 0.04313725],\n",
       "         [0.05098039, 0.04313725, 0.04313725]],\n",
       "\n",
       "        [[0.05098039, 0.03921569, 0.03921569],\n",
       "         [0.04705882, 0.03921569, 0.03921569],\n",
       "         [0.05098039, 0.03921569, 0.04313725],\n",
       "         ...,\n",
       "         [0.04705882, 0.03529412, 0.04313725],\n",
       "         [0.04705882, 0.03529412, 0.03921569],\n",
       "         [0.04705882, 0.03529412, 0.04313725]]],\n",
       "\n",
       "\n",
       "       [[[0.08627451, 0.12156863, 0.15686275],\n",
       "         [0.09019608, 0.1254902 , 0.15294118],\n",
       "         [0.09803922, 0.12941176, 0.14901961],\n",
       "         ...,\n",
       "         [0.08627451, 0.11764706, 0.15686275],\n",
       "         [0.09803922, 0.12941176, 0.17254902],\n",
       "         [0.10980392, 0.1372549 , 0.16470588]],\n",
       "\n",
       "        [[0.08627451, 0.12941176, 0.16078431],\n",
       "         [0.08627451, 0.12941176, 0.15686275],\n",
       "         [0.09019608, 0.12941176, 0.14901961],\n",
       "         ...,\n",
       "         [0.10980392, 0.14901961, 0.18823529],\n",
       "         [0.11372549, 0.14117647, 0.17254902],\n",
       "         [0.10588235, 0.12941176, 0.14117647]],\n",
       "\n",
       "        [[0.09019608, 0.12941176, 0.15686275],\n",
       "         [0.09803922, 0.13333333, 0.15686275],\n",
       "         [0.09411765, 0.12941176, 0.15294118],\n",
       "         ...,\n",
       "         [0.10196078, 0.1372549 , 0.17647059],\n",
       "         [0.10196078, 0.1254902 , 0.14509804],\n",
       "         [0.09803922, 0.11372549, 0.12156863]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.14509804, 0.16470588, 0.17647059],\n",
       "         [0.14117647, 0.16470588, 0.17254902],\n",
       "         [0.14509804, 0.17647059, 0.18431373],\n",
       "         ...,\n",
       "         [0.16862745, 0.18823529, 0.19607843],\n",
       "         [0.16078431, 0.17254902, 0.18431373],\n",
       "         [0.12941176, 0.1372549 , 0.14117647]],\n",
       "\n",
       "        [[0.1254902 , 0.15294118, 0.15686275],\n",
       "         [0.11764706, 0.14509804, 0.15294118],\n",
       "         [0.12156863, 0.14901961, 0.16078431],\n",
       "         ...,\n",
       "         [0.15686275, 0.18039216, 0.19607843],\n",
       "         [0.15294118, 0.17647059, 0.19607843],\n",
       "         [0.15686275, 0.17254902, 0.18431373]],\n",
       "\n",
       "        [[0.1254902 , 0.15294118, 0.15294118],\n",
       "         [0.14117647, 0.16078431, 0.16470588],\n",
       "         [0.14509804, 0.16470588, 0.17254902],\n",
       "         ...,\n",
       "         [0.14901961, 0.17254902, 0.18039216],\n",
       "         [0.14117647, 0.16470588, 0.17647059],\n",
       "         [0.14509804, 0.16862745, 0.18039216]]],\n",
       "\n",
       "\n",
       "       [[[0.90196078, 0.96470588, 0.98823529],\n",
       "         [0.9254902 , 0.98039216, 0.99607843],\n",
       "         [0.93333333, 0.98823529, 1.        ],\n",
       "         ...,\n",
       "         [0.94117647, 1.        , 1.        ],\n",
       "         [0.95294118, 1.        , 1.        ],\n",
       "         [0.95686275, 1.        , 1.        ]],\n",
       "\n",
       "        [[0.82745098, 0.91372549, 0.95294118],\n",
       "         [0.84705882, 0.9254902 , 0.95294118],\n",
       "         [0.8627451 , 0.9372549 , 0.95686275],\n",
       "         ...,\n",
       "         [0.89803922, 1.        , 1.        ],\n",
       "         [0.90980392, 1.        , 1.        ],\n",
       "         [0.91764706, 1.        , 1.        ]],\n",
       "\n",
       "        [[0.83137255, 0.91372549, 0.96078431],\n",
       "         [0.83137255, 0.91764706, 0.95294118],\n",
       "         [0.85098039, 0.92941176, 0.95294118],\n",
       "         ...,\n",
       "         [0.88627451, 1.        , 1.        ],\n",
       "         [0.89411765, 1.        , 1.        ],\n",
       "         [0.89411765, 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.14117647, 0.14901961, 0.16470588],\n",
       "         [0.15686275, 0.17254902, 0.18431373],\n",
       "         [0.14901961, 0.16862745, 0.18431373],\n",
       "         ...,\n",
       "         [0.12941176, 0.12941176, 0.14117647],\n",
       "         [0.11764706, 0.1254902 , 0.13333333],\n",
       "         [0.1254902 , 0.12941176, 0.13333333]],\n",
       "\n",
       "        [[0.13333333, 0.14117647, 0.14509804],\n",
       "         [0.13333333, 0.14901961, 0.15686275],\n",
       "         [0.12156863, 0.14509804, 0.15686275],\n",
       "         ...,\n",
       "         [0.1254902 , 0.12941176, 0.14117647],\n",
       "         [0.11372549, 0.12156863, 0.13333333],\n",
       "         [0.12156863, 0.1254902 , 0.1372549 ]],\n",
       "\n",
       "        [[0.12156863, 0.13333333, 0.1372549 ],\n",
       "         [0.12941176, 0.1372549 , 0.14509804],\n",
       "         [0.1254902 , 0.13333333, 0.14117647],\n",
       "         ...,\n",
       "         [0.1254902 , 0.1254902 , 0.1372549 ],\n",
       "         [0.12156863, 0.1254902 , 0.14117647],\n",
       "         [0.1254902 , 0.12941176, 0.14509804]]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 18,  7, ...,  8,  4,  8])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27446, 43)\n",
      "(11763, 43)\n"
     ]
    }
   ],
   "source": [
    "y_train2 = keras.utils.to_categorical(y_train2, NUM_CATEGORIES)\n",
    "y_val2 = keras.utils.to_categorical(y_val2, NUM_CATEGORIES)\n",
    "\n",
    "print(y_train2.shape)\n",
    "print(y_val2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking if y_train from johns is same as this y_train2 one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identical\n"
     ]
    }
   ],
   "source": [
    "if john_label.all() == y_train2.all():\n",
    "    print(\"identical\")\n",
    "else:\n",
    "    print(\"not the same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identical\n"
     ]
    }
   ],
   "source": [
    "if john_data.all() == X_train2.all():\n",
    "    print(\"identical\")\n",
    "else:\n",
    "    print(\"not the same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,channels)),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Dense(43, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 1\n",
    "\n",
    "opt = tf.keras.optimizers.legacy.Adam(lr=lr, decay=lr / (epochs * 0.5))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659/858 [======================>.......] - ETA: 22s - loss: 1.2880 - accuracy: 0.6540"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "history = model.fit(aug.flow(X_train2, y_train2, batch_size=32), epochs=epochs, validation_data=(X_val2, y_val2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = np.load('30_original_test_data.npy')\n",
    "test_labels2 = np.load('30_original_test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = test_data2/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 13s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(model.predict(test_data2), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42., 42., 42., ..., 42., 42., 42.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data accuracy:  0.5859065716547902\n"
     ]
    }
   ],
   "source": [
    "#Accuracy with the test data\n",
    "print('Test Data accuracy: ',accuracy_score(test_labels2, pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(test_labels2, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       1.00      0.01      0.01     12630\n",
      "\n",
      "    accuracy                           0.01     12630\n",
      "   macro avg       0.02      0.00      0.00     12630\n",
      "weighted avg       1.00      0.01      0.01     12630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_labels2, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bright-dark filter dataset through the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('array_pixels_training.npy')\n",
    "training_label = np.load('array_pixels_label.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95460, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (66822, 32, 32, 3)\n",
      "X_valid.shape (28638, 32, 32, 3)\n",
      "y_train.shape (66822,)\n",
      "y_valid.shape (28638,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(training_data, training_label, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "X_train = X_train \n",
    "X_val = X_val\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_valid.shape\", X_val.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"y_valid.shape\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66822, 43)\n",
      "(28638, 43)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
    "y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Dense(43, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 1\n",
    "\n",
    "opt = tf.keras.optimizers.legacy.Adam(lr=lr, decay=lr / (epochs * 0.5))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2089/2089 [==============================] - 213s 101ms/step - loss: 4.2762 - accuracy: 0.0235 - val_loss: 3.8165 - val_accuracy: 0.0224\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "history = model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('array_pixels_test.npy')\n",
    "test_labels = np.load('array_test_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 8s 20ms/step\n",
      "Test Data accuracy:  0.023752969121140142\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = test_data\n",
    "\n",
    "pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "#Accuracy with the test data\n",
    "print('Test Data accuracy: ',accuracy_score(test_labels, pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(test_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       1.00      0.00      0.00     12630\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.00     12630\n",
      "   macro avg       0.03      0.00      0.00     12630\n",
      "weighted avg       1.00      0.00      0.00     12630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc_env",
   "language": "python",
   "name": "hpc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
