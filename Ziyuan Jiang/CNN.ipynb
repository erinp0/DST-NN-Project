{"cells":[{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import accuracy_score\n","np.random.seed(42)\n","\n","from matplotlib import style\n","style.use('fivethirtyeight')"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["data_dir = '/Users/ziyuanjiang/Downloads/archive'\n","train_path = '/Users/ziyuanjiang/Downloads/archive/Train'\n","test_path = '/Users/ziyuanjiang/Downloads/archive/Test'\n","\n","# Resizing the images to 30x30x3\n","IMG_HEIGHT = 30\n","IMG_WIDTH = 30\n","channels = 3"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["NUM_CATEGORIES = len(os.listdir(train_path))\n","NUM_CATEGORIES = NUM_CATEGORIES - 1"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["# Label Overview\n","classes = { 0:'Speed limit (20km/h)',\n","            1:'Speed limit (30km/h)', \n","            2:'Speed limit (50km/h)', \n","            3:'Speed limit (60km/h)', \n","            4:'Speed limit (70km/h)', \n","            5:'Speed limit (80km/h)', \n","            6:'End of speed limit (80km/h)', \n","            7:'Speed limit (100km/h)', \n","            8:'Speed limit (120km/h)', \n","            9:'No passing', \n","            10:'No passing veh over 3.5 tons', \n","            11:'Right-of-way at intersection', \n","            12:'Priority road', \n","            13:'Yield', \n","            14:'Stop', \n","            15:'No vehicles', \n","            16:'Veh > 3.5 tons prohibited', \n","            17:'No entry', \n","            18:'General caution', \n","            19:'Dangerous curve left', \n","            20:'Dangerous curve right', \n","            21:'Double curve', \n","            22:'Bumpy road', \n","            23:'Slippery road', \n","            24:'Road narrows on the right', \n","            25:'Road work', \n","            26:'Traffic signals', \n","            27:'Pedestrians', \n","            28:'Children crossing', \n","            29:'Bicycles crossing', \n","            30:'Beware of ice/snow',\n","            31:'Wild animals crossing', \n","            32:'End speed + passing limits', \n","            33:'Turn right ahead', \n","            34:'Turn left ahead', \n","            35:'Ahead only', \n","            36:'Go straight or right', \n","            37:'Go straight or left', \n","            38:'Keep right', \n","            39:'Keep left', \n","            40:'Roundabout mandatory', \n","            41:'End of no passing', \n","            42:'End no passing veh > 3.5 tons' }"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(39209, 30, 30, 3) (39209,)\n"]}],"source":["image_data = []\n","image_labels = []\n","\n","for i in range(NUM_CATEGORIES):\n","    path = data_dir + '/Train/' + str(i)\n","    images = os.listdir(path)\n","\n","    for img in images:\n","        try:\n","            image = cv2.imread(path + '/' + img)\n","            image_fromarray = Image.fromarray(image, 'RGB')\n","            resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n","            image_data.append(np.array(resize_image))\n","            image_labels.append(i)\n","        except:\n","            print(\"Error in \" + img)\n","\n","# Changing the list to numpy array\n","image_data = np.array(image_data)\n","image_labels = np.array(image_labels)\n","\n","print(image_data.shape, image_labels.shape)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["shuffle_indexes = np.arange(image_data.shape[0])\n","np.random.shuffle(shuffle_indexes)\n","image_data = image_data[shuffle_indexes]\n","image_labels = image_labels[shuffle_indexes]"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train.shape (27446, 30, 30, 3)\n","X_valid.shape (11763, 30, 30, 3)\n","y_train.shape (27446,)\n","y_valid.shape (11763,)\n"]}],"source":["X_train, X_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.3, random_state=42, shuffle=True)\n","\n","X_train = X_train/255 \n","X_val = X_val/255\n","\n","print(\"X_train.shape\", X_train.shape)\n","print(\"X_valid.shape\", X_val.shape)\n","print(\"y_train.shape\", y_train.shape)\n","print(\"y_valid.shape\", y_val.shape)"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(27446, 43)\n","(11763, 43)\n"]}],"source":["y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n","y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n","\n","print(y_train.shape)\n","print(y_val.shape)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["model = keras.models.Sequential([    \n","    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,channels)),\n","    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n","    keras.layers.MaxPool2D(pool_size=(2, 2)),\n","    keras.layers.BatchNormalization(axis=-1),\n","    \n","    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n","    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n","    keras.layers.MaxPool2D(pool_size=(2, 2)),\n","    keras.layers.BatchNormalization(axis=-1),\n","    \n","    keras.layers.Flatten(),\n","    keras.layers.Dense(512, activation='relu'),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dropout(rate=0.5),\n","    \n","    keras.layers.Dense(43, activation='softmax')\n","])"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["lr = 0.001\n","epochs = 1\n","\n","opt = Adam(lr=lr, decay=lr / (epochs * 0.5))\n","model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train for 858 steps, validate on 11763 samples\n","858/858 [==============================] - 205s 238ms/step - loss: 0.3282 - accuracy: 0.9016 - val_loss: 0.0200 - val_accuracy: 0.9952\n"]}],"source":["aug = ImageDataGenerator(\n","    rotation_range=10,\n","    zoom_range=0.15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.15,\n","    horizontal_flip=False,\n","    vertical_flip=False,\n","    fill_mode=\"nearest\")\n","\n","history = model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=epochs, validation_data=(X_val, y_val))"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Data accuracy:  96.71417260490894\n"]}],"source":["test = pd.read_csv(data_dir + '/Test.csv')\n","\n","labels = test[\"ClassId\"].values\n","imgs = test[\"Path\"].values\n","\n","data =[]\n","\n","for img in imgs:\n","    try:\n","        image = cv2.imread(data_dir + '/' +img)\n","        image_fromarray = Image.fromarray(image, 'RGB')\n","        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n","        data.append(np.array(resize_image))\n","    except:\n","        print(\"Error in \" + img)\n","X_test = np.array(data)\n","X_test = X_test/255\n","\n","pred = model.predict_classes(X_test)\n","\n","#Accuracy with the test data\n","print('Test Data accuracy: ',accuracy_score(labels, pred)*100)"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","cf = confusion_matrix(labels, pred)"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.94      0.97      0.95        60\n","           1       0.96      1.00      0.98       720\n","           2       0.99      0.98      0.98       750\n","           3       0.97      0.92      0.95       450\n","           4       0.99      0.98      0.98       660\n","           5       0.93      0.98      0.96       630\n","           6       0.99      0.98      0.99       150\n","           7       0.99      0.97      0.98       450\n","           8       0.98      0.98      0.98       450\n","           9       1.00      1.00      1.00       480\n","          10       1.00      0.99      1.00       660\n","          11       1.00      0.98      0.99       420\n","          12       0.99      0.91      0.95       690\n","          13       0.99      1.00      1.00       720\n","          14       0.99      1.00      0.99       270\n","          15       0.92      1.00      0.96       210\n","          16       1.00      0.99      1.00       150\n","          17       1.00      0.90      0.95       360\n","          18       0.97      0.88      0.93       390\n","          19       0.75      1.00      0.86        60\n","          20       0.74      0.98      0.84        90\n","          21       0.87      0.67      0.75        90\n","          22       0.99      0.89      0.94       120\n","          23       0.94      1.00      0.97       150\n","          24       0.97      0.83      0.90        90\n","          25       0.97      0.99      0.98       480\n","          26       0.96      0.98      0.97       180\n","          27       0.62      0.98      0.76        60\n","          28       0.99      1.00      1.00       150\n","          29       0.87      1.00      0.93        90\n","          30       0.97      0.77      0.86       150\n","          31       0.96      0.99      0.97       270\n","          32       1.00      0.92      0.96        60\n","          33       0.97      1.00      0.98       210\n","          34       0.97      1.00      0.98       120\n","          35       0.99      0.99      0.99       390\n","          36       0.93      1.00      0.96       120\n","          37       0.89      0.98      0.94        60\n","          38       1.00      0.96      0.98       690\n","          39       0.80      0.99      0.89        90\n","          40       0.72      0.97      0.82        90\n","          41       0.92      1.00      0.96        60\n","          42       1.00      1.00      1.00        90\n","\n","    accuracy                           0.97     12630\n","   macro avg       0.94      0.96      0.95     12630\n","weighted avg       0.97      0.97      0.97     12630\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(labels, pred))"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
