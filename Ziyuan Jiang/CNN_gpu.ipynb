{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(42)\n",
    "\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "\n",
    "class ParallelModel(keras.models.Model):\n",
    "    \"\"\"Subclasses the standard Keras Model and adds multi-GPU support.\n",
    "    It works by creating a copy of the model on each GPU. Then it slices\n",
    "    the inputs and sends a slice to each copy of the model, and then\n",
    "    merges the outputs together and applies the loss on the combined\n",
    "    outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, keras_model, gpu_count):\n",
    "        \"\"\"Class constructor.\n",
    "        keras_model: The Keras model to parallelize\n",
    "        gpu_count: Number of GPUs. Must be > 1\n",
    "        \"\"\"\n",
    "        super(ParallelModel, self).__init__() # Thanks to @greatken999 for fixing bugs\n",
    "        self.inner_model = keras_model\n",
    "        self.gpu_count = gpu_count\n",
    "        merged_outputs = self.make_parallel()\n",
    "        super(ParallelModel, self).__init__(inputs=self.inner_model.inputs,\n",
    "                                            outputs=merged_outputs)\n",
    "\n",
    "    def __getattribute__(self, attrname):\n",
    "        \"\"\"Redirect loading and saving methods to the inner model. That's where\n",
    "        the weights are stored.\"\"\"\n",
    "        if 'load' in attrname or 'save' in attrname:\n",
    "            return getattr(self.inner_model, attrname)\n",
    "        return super(ParallelModel, self).__getattribute__(attrname)\n",
    "\n",
    "    def summary(self, *args, **kwargs):\n",
    "        \"\"\"Override summary() to display summaries of both, the wrapper\n",
    "        and inner models.\"\"\"\n",
    "        super(ParallelModel, self).summary(*args, **kwargs)\n",
    "        self.inner_model.summary(*args, **kwargs)\n",
    "\n",
    "    def make_parallel(self):\n",
    "        \"\"\"Creates a new wrapper model that consists of multiple replicas of\n",
    "        the original model placed on different GPUs.\n",
    "        \"\"\"\n",
    "        # Slice inputs. Slice inputs on the CPU to avoid sending a copy\n",
    "        # of the full inputs to all GPUs. Saves on bandwidth and memory.\n",
    "        input_slices = {name: tf.split(x, self.gpu_count)\n",
    "                        for name, x in zip(self.inner_model.input_names,\n",
    "                                           self.inner_model.inputs)}\n",
    "\n",
    "        output_names = self.inner_model.output_names\n",
    "        outputs_all = []\n",
    "        for i in range(len(self.inner_model.outputs)):\n",
    "            outputs_all.append([])\n",
    "\n",
    "        # Run the model call() on each GPU to place the ops there\n",
    "        for i in range(self.gpu_count):\n",
    "            with tf.device('/gpu:%d' % i):\n",
    "                with tf.name_scope('tower_%d' % i):\n",
    "                    # Run a slice of inputs through this replica\n",
    "                    zipped_inputs = zip(self.inner_model.input_names,\n",
    "                                        self.inner_model.inputs)\n",
    "                    inputs = [\n",
    "                        KL.Lambda(lambda s: input_slices[name][i],\n",
    "                                  output_shape=lambda s: (None,) + s[1:])(tensor)\n",
    "                        for name, tensor in zipped_inputs]\n",
    "                    # Create the model replica and get the outputs\n",
    "                    outputs = self.inner_model(inputs)\n",
    "                    if not isinstance(outputs, list):\n",
    "                        outputs = [outputs]\n",
    "                    # Save the outputs for merging back together later\n",
    "                    for l, o in enumerate(outputs):\n",
    "                        outputs_all[l].append(o)\n",
    "\n",
    "        # Merge outputs on CPU\n",
    "        with tf.device('/cpu:0'):\n",
    "            merged = []\n",
    "            for outputs, name in zip(outputs_all, output_names):\n",
    "                # If outputs are numbers without dimensions, add a batch dim.\n",
    "                def add_dim(tensor):\n",
    "                    \"\"\"Add a dimension to tensors that don't have any.\"\"\"\n",
    "                    if K.int_shape(tensor) == ():\n",
    "                        return KL.Lambda(lambda t: K.reshape(t, [1, 1]))(tensor)\n",
    "                    return tensor\n",
    "                outputs = list(map(add_dim, outputs))\n",
    "\n",
    "                # Concatenate\n",
    "                merged.append(KL.Concatenate(axis=0, name=name)(outputs))\n",
    "        return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/ziyuanjiang/Downloads/archive'\n",
    "train_path = '/Users/ziyuanjiang/Downloads/archive/Train'\n",
    "test_path = '/Users/ziyuanjiang/Downloads/archive/Test'\n",
    "\n",
    "# Resizing the images to 30x30x3\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CATEGORIES = len(os.listdir(train_path))\n",
    "NUM_CATEGORIES = NUM_CATEGORIES - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Overview\n",
    "classes = { 0:'Speed limit (20km/h)',\n",
    "            1:'Speed limit (30km/h)', \n",
    "            2:'Speed limit (50km/h)', \n",
    "            3:'Speed limit (60km/h)', \n",
    "            4:'Speed limit (70km/h)', \n",
    "            5:'Speed limit (80km/h)', \n",
    "            6:'End of speed limit (80km/h)', \n",
    "            7:'Speed limit (100km/h)', \n",
    "            8:'Speed limit (120km/h)', \n",
    "            9:'No passing', \n",
    "            10:'No passing veh over 3.5 tons', \n",
    "            11:'Right-of-way at intersection', \n",
    "            12:'Priority road', \n",
    "            13:'Yield', \n",
    "            14:'Stop', \n",
    "            15:'No vehicles', \n",
    "            16:'Veh > 3.5 tons prohibited', \n",
    "            17:'No entry', \n",
    "            18:'General caution', \n",
    "            19:'Dangerous curve left', \n",
    "            20:'Dangerous curve right', \n",
    "            21:'Double curve', \n",
    "            22:'Bumpy road', \n",
    "            23:'Slippery road', \n",
    "            24:'Road narrows on the right', \n",
    "            25:'Road work', \n",
    "            26:'Traffic signals', \n",
    "            27:'Pedestrians', \n",
    "            28:'Children crossing', \n",
    "            29:'Bicycles crossing', \n",
    "            30:'Beware of ice/snow',\n",
    "            31:'Wild animals crossing', \n",
    "            32:'End speed + passing limits', \n",
    "            33:'Turn right ahead', \n",
    "            34:'Turn left ahead', \n",
    "            35:'Ahead only', \n",
    "            36:'Go straight or right', \n",
    "            37:'Go straight or left', \n",
    "            38:'Keep right', \n",
    "            39:'Keep left', \n",
    "            40:'Roundabout mandatory', \n",
    "            41:'End of no passing', \n",
    "            42:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 32, 32, 3) (39209,)\n"
     ]
    }
   ],
   "source": [
    "image_data = []\n",
    "image_labels = []\n",
    "\n",
    "for i in range(NUM_CATEGORIES):\n",
    "    path = data_dir + '/Train/' + str(i)\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    for img in images:\n",
    "        try:\n",
    "            image = cv2.imread(path + '/' + img)\n",
    "            image_fromarray = Image.fromarray(image, 'RGB')\n",
    "            resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n",
    "            image_data.append(np.array(resize_image))\n",
    "            image_labels.append(i)\n",
    "        except:\n",
    "            print(\"Error in \" + img)\n",
    "\n",
    "# Changing the list to numpy array\n",
    "image_data = np.array(image_data)\n",
    "image_labels = np.array(image_labels)\n",
    "\n",
    "print(image_data.shape, image_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_indexes = np.arange(image_data.shape[0])\n",
    "np.random.shuffle(shuffle_indexes)\n",
    "image_data = image_data[shuffle_indexes]\n",
    "image_labels = image_labels[shuffle_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (27446, 32, 32, 3)\n",
      "X_valid.shape (11763, 32, 32, 3)\n",
      "y_train.shape (27446,)\n",
      "y_valid.shape (11763,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "X_train = X_train/255 \n",
    "X_val = X_val/255\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_valid.shape\", X_val.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"y_valid.shape\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27446, 43)\n",
      "(11763, 43)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
    "y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,channels)),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Dense(43, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 5\n",
    "\n",
    "opt = Adam(lr=lr, decay=lr / (epochs * 0.5))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "Parallel_Model = multi_gpu_model(model, gpus=8)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "858/858 [==============================] - 256s 299ms/step - loss: 1.1200 - accuracy: 0.6938 - val_loss: 0.0662 - val_accuracy: 0.9838\n",
      "Epoch 2/5\n",
      "858/858 [==============================] - 252s 294ms/step - loss: 0.1641 - accuracy: 0.9498 - val_loss: 0.0265 - val_accuracy: 0.9918\n",
      "Epoch 3/5\n",
      "858/858 [==============================] - 258s 300ms/step - loss: 0.0820 - accuracy: 0.9755 - val_loss: 0.0112 - val_accuracy: 0.9980\n",
      "Epoch 4/5\n",
      "858/858 [==============================] - 249s 291ms/step - loss: 0.0548 - accuracy: 0.9840 - val_loss: 0.0125 - val_accuracy: 0.9965\n",
      "Epoch 5/5\n",
      "858/858 [==============================] - 254s 296ms/step - loss: 0.0439 - accuracy: 0.9862 - val_loss: 0.0122 - val_accuracy: 0.9968\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "history = model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data accuracy:  96.76959619952494\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(data_dir + '/Test.csv')\n",
    "\n",
    "labels = test[\"ClassId\"].values\n",
    "imgs = test[\"Path\"].values\n",
    "\n",
    "data =[]\n",
    "\n",
    "for img in imgs:\n",
    "    try:\n",
    "        image = cv2.imread(data_dir + '/' +img)\n",
    "        image_fromarray = Image.fromarray(image, 'RGB')\n",
    "        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n",
    "        data.append(np.array(resize_image))\n",
    "    except:\n",
    "        print(\"Error in \" + img)\n",
    "X_test = np.array(data)\n",
    "X_test = X_test/255\n",
    "\n",
    "pred = model.predict_classes(X_test)\n",
    "\n",
    "#Accuracy with the test data\n",
    "print('Test Data accuracy: ',accuracy_score(labels, pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        60\n",
      "           1       0.99      1.00      0.99       720\n",
      "           2       0.99      0.99      0.99       750\n",
      "           3       0.99      0.93      0.96       450\n",
      "           4       1.00      0.98      0.99       660\n",
      "           5       0.93      0.99      0.96       630\n",
      "           6       1.00      0.89      0.94       150\n",
      "           7       1.00      0.92      0.96       450\n",
      "           8       0.93      0.98      0.95       450\n",
      "           9       0.99      1.00      0.99       480\n",
      "          10       1.00      0.99      1.00       660\n",
      "          11       1.00      0.95      0.97       420\n",
      "          12       1.00      0.93      0.96       690\n",
      "          13       1.00      0.99      1.00       720\n",
      "          14       1.00      1.00      1.00       270\n",
      "          15       0.96      1.00      0.98       210\n",
      "          16       0.99      1.00      1.00       150\n",
      "          17       1.00      0.92      0.96       360\n",
      "          18       0.99      0.86      0.92       390\n",
      "          19       0.97      1.00      0.98        60\n",
      "          20       0.93      1.00      0.96        90\n",
      "          21       0.72      0.98      0.83        90\n",
      "          22       0.97      0.99      0.98       120\n",
      "          23       0.97      0.99      0.98       150\n",
      "          24       0.98      0.98      0.98        90\n",
      "          25       0.95      0.99      0.97       480\n",
      "          26       0.88      1.00      0.94       180\n",
      "          27       1.00      0.50      0.67        60\n",
      "          28       0.99      0.99      0.99       150\n",
      "          29       0.79      1.00      0.88        90\n",
      "          30       0.80      0.73      0.77       150\n",
      "          31       0.99      1.00      0.99       270\n",
      "          32       1.00      0.98      0.99        60\n",
      "          33       0.92      0.99      0.96       210\n",
      "          34       0.93      1.00      0.96       120\n",
      "          35       1.00      0.98      0.99       390\n",
      "          36       0.91      1.00      0.95       120\n",
      "          37       0.95      1.00      0.98        60\n",
      "          38       0.96      0.99      0.98       690\n",
      "          39       0.97      0.87      0.92        90\n",
      "          40       0.63      0.98      0.77        90\n",
      "          41       0.93      0.95      0.94        60\n",
      "          42       0.98      0.98      0.98        90\n",
      "\n",
      "    accuracy                           0.97     12630\n",
      "   macro avg       0.95      0.96      0.95     12630\n",
      "weighted avg       0.97      0.97      0.97     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyuanjiang/opt/anaconda3/envs/as3cnn/lib/python3.7/site-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
