{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model\n",
    "This document mainly covers the training and testing of the original CNN model. The images are first pre-processed, resized and shuffled, and in the second half of the code, several GPUs are used to accelerate the code with significant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the base package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a data set\n",
    "data_dir = '/Users/ziyuanjiang/Downloads/archive'\n",
    "train_path = '/Users/ziyuanjiang/Downloads/archive/Train'\n",
    "test_path = '/Users/ziyuanjiang/Downloads/archive/Test'\n",
    "\n",
    "NUM_CATEGORIES = len(os.listdir(train_path))\n",
    "NUM_CATEGORIES = NUM_CATEGORIES - 1\n",
    "\n",
    "# Resizing the images to 32x32x3\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Overview\n",
    "classes = { 0:'Speed limit (20km/h)',\n",
    "            1:'Speed limit (30km/h)', \n",
    "            2:'Speed limit (50km/h)', \n",
    "            3:'Speed limit (60km/h)', \n",
    "            4:'Speed limit (70km/h)', \n",
    "            5:'Speed limit (80km/h)', \n",
    "            6:'End of speed limit (80km/h)', \n",
    "            7:'Speed limit (100km/h)', \n",
    "            8:'Speed limit (120km/h)', \n",
    "            9:'No passing', \n",
    "            10:'No passing veh over 3.5 tons', \n",
    "            11:'Right-of-way at intersection', \n",
    "            12:'Priority road', \n",
    "            13:'Yield', \n",
    "            14:'Stop', \n",
    "            15:'No vehicles', \n",
    "            16:'Veh > 3.5 tons prohibited', \n",
    "            17:'No entry', \n",
    "            18:'General caution', \n",
    "            19:'Dangerous curve left', \n",
    "            20:'Dangerous curve right', \n",
    "            21:'Double curve', \n",
    "            22:'Bumpy road', \n",
    "            23:'Slippery road', \n",
    "            24:'Road narrows on the right', \n",
    "            25:'Road work', \n",
    "            26:'Traffic signals', \n",
    "            27:'Pedestrians', \n",
    "            28:'Children crossing', \n",
    "            29:'Bicycles crossing', \n",
    "            30:'Beware of ice/snow',\n",
    "            31:'Wild animals crossing', \n",
    "            32:'End speed + passing limits', \n",
    "            33:'Turn right ahead', \n",
    "            34:'Turn left ahead', \n",
    "            35:'Ahead only', \n",
    "            36:'Go straight or right', \n",
    "            37:'Go straight or left', \n",
    "            38:'Keep right', \n",
    "            39:'Keep left', \n",
    "            40:'Roundabout mandatory', \n",
    "            41:'End of no passing', \n",
    "            42:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 32, 32, 3) (39209,)\n"
     ]
    }
   ],
   "source": [
    "#Pre-processing of images, resizing of images\n",
    "image_data = []\n",
    "image_labels = []\n",
    "\n",
    "for i in range(NUM_CATEGORIES):\n",
    "    path = data_dir + '/Train/' + str(i)\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    for img in images:\n",
    "        try:\n",
    "            image = cv2.imread(path + '/' + img)\n",
    "            image_fromarray = Image.fromarray(image, 'RGB')\n",
    "            resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n",
    "            image_data.append(np.array(resize_image))\n",
    "            image_labels.append(i)\n",
    "        except:\n",
    "            print(\"Error in \" + img)\n",
    "\n",
    "# Changing the list to numpy array\n",
    "image_data = np.array(image_data)\n",
    "image_labels = np.array(image_labels)\n",
    "\n",
    "print(image_data.shape, image_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (27446, 32, 32, 3)\n",
      "X_valid.shape (11763, 32, 32, 3)\n",
      "y_train.shape (27446,)\n",
      "y_valid.shape (11763,)\n"
     ]
    }
   ],
   "source": [
    "#Rotate the image to add variation to the data set\n",
    "shuffle_indexes = np.arange(image_data.shape[0])\n",
    "np.random.shuffle(shuffle_indexes)\n",
    "image_data = image_data[shuffle_indexes]\n",
    "image_labels = image_labels[shuffle_indexes]\n",
    "X_train, X_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "X_train = X_train/255 \n",
    "X_val = X_val/255\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_valid.shape\", X_val.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"y_valid.shape\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27446, 43)\n",
      "(11763, 43)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
    "y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the structure of the CNN model\n",
    "model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,channels)),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Dense(43, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 1,761,099\n",
      "Trainable params: 1,759,755\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting parameters for CNN model training\n",
    "lr = 0.001\n",
    "epochs = 5\n",
    "\n",
    "opt = Adam(lr=lr, decay=lr / (epochs * 0.5))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use gpu to speed up operation\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "Parallel_Model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "858/858 [==============================] - 256s 299ms/step - loss: 1.1200 - accuracy: 0.6938 - val_loss: 0.0662 - val_accuracy: 0.9838\n",
      "Epoch 2/5\n",
      "858/858 [==============================] - 252s 294ms/step - loss: 0.1641 - accuracy: 0.9498 - val_loss: 0.0265 - val_accuracy: 0.9918\n",
      "Epoch 3/5\n",
      "858/858 [==============================] - 258s 300ms/step - loss: 0.0820 - accuracy: 0.9755 - val_loss: 0.0112 - val_accuracy: 0.9980\n",
      "Epoch 4/5\n",
      "858/858 [==============================] - 249s 291ms/step - loss: 0.0548 - accuracy: 0.9840 - val_loss: 0.0125 - val_accuracy: 0.9965\n",
      "Epoch 5/5\n",
      "858/858 [==============================] - 254s 296ms/step - loss: 0.0439 - accuracy: 0.9862 - val_loss: 0.0122 - val_accuracy: 0.9968\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "history = model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data accuracy:  96.76959619952494\n"
     ]
    }
   ],
   "source": [
    "#Running the test set\n",
    "test = pd.read_csv(data_dir + '/Test.csv')\n",
    "\n",
    "labels = test[\"ClassId\"].values\n",
    "imgs = test[\"Path\"].values\n",
    "\n",
    "data =[]\n",
    "\n",
    "for img in imgs:\n",
    "    try:\n",
    "        image = cv2.imread(data_dir + '/' +img)\n",
    "        image_fromarray = Image.fromarray(image, 'RGB')\n",
    "        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n",
    "        data.append(np.array(resize_image))\n",
    "    except:\n",
    "        print(\"Error in \" + img)\n",
    "X_test = np.array(data)\n",
    "X_test = X_test/255\n",
    "\n",
    "pred = model.predict_classes(X_test)\n",
    "\n",
    "#Accuracy with the test data\n",
    "print('Test Data accuracy: ',accuracy_score(labels, pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        60\n",
      "           1       0.99      1.00      0.99       720\n",
      "           2       0.99      0.99      0.99       750\n",
      "           3       0.99      0.93      0.96       450\n",
      "           4       1.00      0.98      0.99       660\n",
      "           5       0.93      0.99      0.96       630\n",
      "           6       1.00      0.89      0.94       150\n",
      "           7       1.00      0.92      0.96       450\n",
      "           8       0.93      0.98      0.95       450\n",
      "           9       0.99      1.00      0.99       480\n",
      "          10       1.00      0.99      1.00       660\n",
      "          11       1.00      0.95      0.97       420\n",
      "          12       1.00      0.93      0.96       690\n",
      "          13       1.00      0.99      1.00       720\n",
      "          14       1.00      1.00      1.00       270\n",
      "          15       0.96      1.00      0.98       210\n",
      "          16       0.99      1.00      1.00       150\n",
      "          17       1.00      0.92      0.96       360\n",
      "          18       0.99      0.86      0.92       390\n",
      "          19       0.97      1.00      0.98        60\n",
      "          20       0.93      1.00      0.96        90\n",
      "          21       0.72      0.98      0.83        90\n",
      "          22       0.97      0.99      0.98       120\n",
      "          23       0.97      0.99      0.98       150\n",
      "          24       0.98      0.98      0.98        90\n",
      "          25       0.95      0.99      0.97       480\n",
      "          26       0.88      1.00      0.94       180\n",
      "          27       1.00      0.50      0.67        60\n",
      "          28       0.99      0.99      0.99       150\n",
      "          29       0.79      1.00      0.88        90\n",
      "          30       0.80      0.73      0.77       150\n",
      "          31       0.99      1.00      0.99       270\n",
      "          32       1.00      0.98      0.99        60\n",
      "          33       0.92      0.99      0.96       210\n",
      "          34       0.93      1.00      0.96       120\n",
      "          35       1.00      0.98      0.99       390\n",
      "          36       0.91      1.00      0.95       120\n",
      "          37       0.95      1.00      0.98        60\n",
      "          38       0.96      0.99      0.98       690\n",
      "          39       0.97      0.87      0.92        90\n",
      "          40       0.63      0.98      0.77        90\n",
      "          41       0.93      0.95      0.94        60\n",
      "          42       0.98      0.98      0.98        90\n",
      "\n",
      "    accuracy                           0.97     12630\n",
      "   macro avg       0.95      0.96      0.95     12630\n",
      "weighted avg       0.97      0.97      0.97     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(labels, pred)\n",
    "print(classification_report(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyuanjiang/opt/anaconda3/envs/as3cnn/lib/python3.7/site-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
