{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e5795d",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "We will now classify the test sets using our two models and compare the average F1-scores.\n",
    "\n",
    "The F1-score is the harmonic mean between the precision and recall, and so a good measure of success when precision and recall are equally important. This is explained further, along with other options for evaluation metrics within multi-class classification, in [Evaluating Multi-Class Classifiers](https://medium.com/apprentice-journal/evaluating-multi-class-classifiers-12b2946e755b#:~:text=Two%20methods%2C%20micro%2Daveraging%2C,class%20to%20calculate%20the%20average.). If there are fewer classes, other techniques might be appropriate to look at alongside F1-scores, such as confusion matrices.\n",
    "\n",
    "The F1-score is given for each separate class, but we want an overall score for all the classes. We therefore choose to take the macro average. The macro-average is the unweighted average of the F1-scores of each class. This means that each class is treated as equally important regardless of how many instances there are of this class. This corrects for imbalanced classes within the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90729945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17457377",
   "metadata": {},
   "source": [
    "## 2. Load in test sets\n",
    "\n",
    "We will be looking at each one separately as well as the combined scores, in order to see the strengths and weaknesses of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e26e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=np.load('32_filter_test_label.npy')\n",
    "\n",
    "orig_test=np.load('32_filter_test_data.npy')\n",
    "noisy_test=np.load('noisy_test.npy')\n",
    "colour_patch_test=np.load('colour_patched_test.npy')\n",
    "other_patch_test=np.load('other_patched_test.npy')\n",
    "same_patch_test=np.load('same_patched_test.npy')\n",
    "cw_005_advs_test=np.load('005_cw_advs.npy')\n",
    "cw_02_advs_test=np.load('02_cw_advs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64a498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_advs_test=np.concatenate((cw_005_advs_test, cw_02_advs_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60c9b0",
   "metadata": {},
   "source": [
    "## 2. Basic CNN \n",
    "First we load in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "979a7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model=tf.keras.models.load_model('basic_cnn_model_filter.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b52c6",
   "metadata": {},
   "source": [
    "Then we get the predictions for the test sets. We begin with the original test set.\n",
    "\n",
    "The first line below returns probabilities across the classes. We then take the index of the maximum in each row to be the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d5efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 12s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = cnn_model.predict(orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c0bdad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred_prob, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009d6f0",
   "metadata": {},
   "source": [
    "We can look at the classification report if we want, which shows the precision, recall, F1-score and number of that class in the test set for all of the classes, as well as averages of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7954c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        60\n",
      "           1       0.99      1.00      1.00       720\n",
      "           2       1.00      1.00      1.00       750\n",
      "           3       0.99      0.98      0.98       450\n",
      "           4       1.00      0.99      1.00       660\n",
      "           5       0.93      1.00      0.96       630\n",
      "           6       1.00      0.85      0.92       150\n",
      "           7       1.00      1.00      1.00       450\n",
      "           8       1.00      0.95      0.98       450\n",
      "           9       1.00      1.00      1.00       480\n",
      "          10       1.00      1.00      1.00       660\n",
      "          11       0.99      0.99      0.99       420\n",
      "          12       1.00      1.00      1.00       690\n",
      "          13       1.00      1.00      1.00       720\n",
      "          14       0.97      1.00      0.98       270\n",
      "          15       1.00      1.00      1.00       210\n",
      "          16       1.00      1.00      1.00       150\n",
      "          17       1.00      0.97      0.99       360\n",
      "          18       0.99      0.96      0.97       390\n",
      "          19       1.00      1.00      1.00        60\n",
      "          20       1.00      1.00      1.00        90\n",
      "          21       1.00      0.84      0.92        90\n",
      "          22       0.97      0.95      0.96       120\n",
      "          23       0.96      1.00      0.98       150\n",
      "          24       1.00      0.97      0.98        90\n",
      "          25       0.99      1.00      0.99       480\n",
      "          26       0.90      0.99      0.94       180\n",
      "          27       0.97      0.95      0.96        60\n",
      "          28       0.99      0.99      0.99       150\n",
      "          29       0.98      1.00      0.99        90\n",
      "          30       0.98      0.93      0.96       150\n",
      "          31       0.97      1.00      0.98       270\n",
      "          32       0.98      1.00      0.99        60\n",
      "          33       1.00      1.00      1.00       210\n",
      "          34       1.00      1.00      1.00       120\n",
      "          35       0.99      1.00      1.00       390\n",
      "          36       0.99      1.00      1.00       120\n",
      "          37       0.98      0.98      0.98        60\n",
      "          38       1.00      1.00      1.00       690\n",
      "          39       1.00      0.99      0.99        90\n",
      "          40       1.00      0.99      0.99        90\n",
      "          41       0.95      1.00      0.98        60\n",
      "          42       0.92      0.98      0.95        90\n",
      "\n",
      "    accuracy                           0.99     12630\n",
      "   macro avg       0.99      0.98      0.98     12630\n",
      "weighted avg       0.99      0.99      0.99     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2025a8",
   "metadata": {},
   "source": [
    "But we have chosen to look at the macro average F1-score as our evaluation metric, so we can just report that as so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fbc8140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9832841326326808\n"
     ]
    }
   ],
   "source": [
    "report=classification_report(test_labels, y_pred,output_dict=True)\n",
    "macro_f1 = report['macro avg']['f1-score']\n",
    "print(macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d577c1",
   "metadata": {},
   "source": [
    "We do the same for each of our adversarial test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea2957dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 10s 26ms/step\n",
      "0.9190819000175338\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_noisy = cnn_model.predict(noisy_test)\n",
    "y_pred_noisy = np.argmax(y_pred_prob_noisy, axis=-1)\n",
    "report_noisy=classification_report(test_labels, y_pred_noisy,output_dict=True)\n",
    "macro_f1_noisy = report_noisy['macro avg']['f1-score']\n",
    "print(macro_f1_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "433c28e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 10s 26ms/step\n",
      "0.9422006227902302\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_colour_patch = cnn_model.predict(colour_patch_test)\n",
    "y_pred_colour_patch = np.argmax(y_pred_prob_colour_patch, axis=-1)\n",
    "report_colour_patch=classification_report(test_labels, y_pred_colour_patch,output_dict=True)\n",
    "macro_f1_colour_patch = report_colour_patch['macro avg']['f1-score']\n",
    "print(macro_f1_colour_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a92a891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 11s 27ms/step\n",
      "0.9368071543386852\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_other_patch = cnn_model.predict(other_patch_test)\n",
    "y_pred_other_patch = np.argmax(y_pred_prob_other_patch, axis=-1)\n",
    "report_other_patch=classification_report(test_labels, y_pred_other_patch,output_dict=True)\n",
    "macro_f1_other_patch = report_other_patch['macro avg']['f1-score']\n",
    "print(macro_f1_other_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3217b70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 10s 26ms/step\n",
      "0.9517097250498128\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_same_patch = cnn_model.predict(same_patch_test)\n",
    "y_pred_same_patch = np.argmax(y_pred_prob_same_patch, axis=-1)\n",
    "report_same_patch=classification_report(test_labels, y_pred_same_patch,output_dict=True)\n",
    "macro_f1_same_patch = report_same_patch['macro avg']['f1-score']\n",
    "print(macro_f1_same_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "491e1054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 11s 27ms/step\n",
      "0.02174800572586635\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_cw = cnn_model.predict(cw_advs_test)\n",
    "y_pred_cw = np.argmax(y_pred_prob_cw, axis=-1)\n",
    "report_cw=classification_report(test_labels, y_pred_cw,output_dict=True)\n",
    "macro_f1_cw = report_cw['macro avg']['f1-score']\n",
    "print(macro_f1_cw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d96e0",
   "metadata": {},
   "source": [
    "We can see that the score for the CW adversarial images is very bad. This is because these were created to specifically fool this model. Out of the other adversarial images, the noisy ones have the next lowest score, although it is not very low. Then these are followed by images patched with other images, images with randomly coloured patches, and images patched with the same image.\n",
    "\n",
    "Now we obtain a combined F1-score for how well the model performed on the test set as a whole. This score represents how well the model performs if we say that we care equally about misclassification in each of the separate test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "733e94e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_combined=np.concatenate((y_pred_prob, y_pred_prob_noisy, y_pred_prob_colour_patch, y_pred_prob_other_patch, y_pred_prob_same_patch, y_pred_prob_cw), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92ad80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combined=np.concatenate((y_pred, y_pred_noisy, y_pred_colour_patch, y_pred_other_patch, y_pred_same_patch, y_pred_cw), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb1c786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_repeated=np.concatenate((test_labels, test_labels, test_labels, test_labels, test_labels, test_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0f931f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7623218084605388\n"
     ]
    }
   ],
   "source": [
    "report_combined=classification_report(test_labels_repeated, y_pred_combined,output_dict=True)\n",
    "macro_f1_combined = report_combined['macro avg']['f1-score']\n",
    "print(macro_f1_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7089c",
   "metadata": {},
   "source": [
    "## 3. Model With Defences\n",
    "\n",
    "This model consists of three stages: an autoencoder, a classifier of whether an image is adversarial or not, and then the CNN. So we begin by loading in the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9eccf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder=tf.keras.models.load_model('denoising_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9162df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_classifier=tf.keras.models.load_model('adv_classifier_200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06950e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "defences_cnn=tf.keras.models.load_model('DEFENCE_cnn_200.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c8c54f",
   "metadata": {},
   "source": [
    "First we pass each set of images through the autoencoder. This should remove any noise from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae1300f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 41s 103ms/step\n",
      "395/395 [==============================] - 41s 103ms/step\n",
      "395/395 [==============================] - 40s 102ms/step\n",
      "395/395 [==============================] - 40s 100ms/step\n",
      "395/395 [==============================] - 40s 102ms/step\n",
      "395/395 [==============================] - 41s 103ms/step\n"
     ]
    }
   ],
   "source": [
    "orig_test_autoencoder=autoencoder.predict(orig_test)\n",
    "noisy_test_autoencoder=autoencoder.predict(noisy_test)\n",
    "colour_patch_test_autoencoder=autoencoder.predict(colour_patch_test)\n",
    "other_patch_test_autoencoder=autoencoder.predict(other_patch_test)\n",
    "same_patch_test_autoencoder=autoencoder.predict(same_patch_test)\n",
    "cw_advs_test_autoencoder=autoencoder.predict(cw_advs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9cc939",
   "metadata": {},
   "source": [
    "Next we obtain a classification of whether the image is adversarial or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd15a06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 9s 22ms/step\n",
      "395/395 [==============================] - 9s 23ms/step\n",
      "395/395 [==============================] - 9s 23ms/step\n",
      "395/395 [==============================] - 9s 23ms/step\n",
      "395/395 [==============================] - 9s 23ms/step\n",
      "395/395 [==============================] - 9s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "orig_test_classifications=adv_classifier.predict(orig_test_autoencoder)\n",
    "noisy_test_classifications=adv_classifier.predict(noisy_test_autoencoder)\n",
    "colour_patch_test_classifications=adv_classifier.predict(colour_patch_test_autoencoder)\n",
    "other_patch_test_classifications=adv_classifier.predict(other_patch_test_autoencoder)\n",
    "same_patch_test_classifications=adv_classifier.predict(same_patch_test_autoencoder)\n",
    "cw_advs_test_classifications=adv_classifier.predict(cw_advs_test_autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087bdf80",
   "metadata": {},
   "source": [
    "The above are probabilities so we have to convert these into binary outputs by checking if they are over 0.5 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d7d1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test_classifications_b = np.where(orig_test_classifications[:, 0] > 0.5, 1, 0)\n",
    "noisy_test_classifications_b = np.where(noisy_test_classifications[:, 0] > 0.5, 1, 0)\n",
    "colour_patch_test_classifications_b = np.where(colour_patch_test_classifications[:, 0] > 0.5, 1, 0)\n",
    "other_patch_test_classifications_b = np.where(other_patch_test_classifications[:, 0] > 0.5, 1, 0)\n",
    "same_patch_test_classifications_b = np.where(same_patch_test_classifications[:, 0] > 0.5, 1, 0)\n",
    "cw_advs_test_classifications_b = np.where(cw_advs_test_classifications[:, 0] > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a719afc7",
   "metadata": {},
   "source": [
    "Now we obtain the predicitions using the CNN as we did before, except now we have the extra input of the adversarial classification. \n",
    "\n",
    "We begin with the original test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57559dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 11s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_defence = defences_cnn.predict([orig_test_autoencoder,orig_test_classifications_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40c00748",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_defence = np.argmax(y_pred_prob_defence, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d8e8a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8972372679996006\n"
     ]
    }
   ],
   "source": [
    "report_defence=classification_report(test_labels, y_pred_defence,output_dict=True)\n",
    "macro_f1_defence = report_defence['macro avg']['f1-score']\n",
    "print(macro_f1_defence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09553bd9",
   "metadata": {},
   "source": [
    "Now we move on to the adversarial test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03298eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 10s 26ms/step\n",
      "0.8856664256720654\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_noisy_defence = defences_cnn.predict([noisy_test_autoencoder,noisy_test_classifications_b])\n",
    "y_pred_noisy_defence = np.argmax(y_pred_prob_noisy_defence, axis=-1)\n",
    "report_noisy_defence=classification_report(test_labels, y_pred_noisy_defence,output_dict=True)\n",
    "macro_f1_noisy_defence = report_noisy_defence['macro avg']['f1-score']\n",
    "print(macro_f1_noisy_defence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d8cbe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 11s 27ms/step\n",
      "0.8480705305317889\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_colour_patch_defence = defences_cnn.predict([colour_patch_test_autoencoder,colour_patch_test_classifications_b])\n",
    "y_pred_colour_patch_defence = np.argmax(y_pred_prob_colour_patch_defence, axis=-1)\n",
    "report_colour_patch_defence=classification_report(test_labels, y_pred_colour_patch_defence,output_dict=True)\n",
    "macro_f1_colour_patch_defence = report_colour_patch_defence['macro avg']['f1-score']\n",
    "print(macro_f1_colour_patch_defence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5ddc850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 11s 27ms/step\n",
      "0.855512027419354\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_other_patch_defence = defences_cnn.predict([other_patch_test_autoencoder,other_patch_test_classifications_b])\n",
    "y_pred_other_patch_defence = np.argmax(y_pred_prob_other_patch_defence, axis=-1)\n",
    "report_other_patch_defence=classification_report(test_labels, y_pred_other_patch_defence,output_dict=True)\n",
    "macro_f1_other_patch_defence = report_other_patch_defence['macro avg']['f1-score']\n",
    "print(macro_f1_other_patch_defence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed16f646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 10s 25ms/step\n",
      "0.8697185820849073\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_same_patch_defence = defences_cnn.predict([same_patch_test_autoencoder,same_patch_test_classifications_b])\n",
    "y_pred_same_patch_defence = np.argmax(y_pred_prob_same_patch_defence, axis=-1)\n",
    "report_same_patch_defence=classification_report(test_labels, y_pred_same_patch_defence,output_dict=True)\n",
    "macro_f1_same_patch_defence = report_same_patch_defence['macro avg']['f1-score']\n",
    "print(macro_f1_same_patch_defence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "730509a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 11s 26ms/step\n",
      "0.8691694353521981\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_cw_defence = defences_cnn.predict([cw_advs_test_autoencoder,cw_advs_test_classifications_b])\n",
    "y_pred_cw_defence = np.argmax(y_pred_prob_cw_defence, axis=-1)\n",
    "report_cw_defence=classification_report(test_labels, y_pred_cw_defence,output_dict=True)\n",
    "macro_f1_cw_defence = report_cw_defence['macro avg']['f1-score']\n",
    "print(macro_f1_cw_defence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09b3aa",
   "metadata": {},
   "source": [
    "And then we have a combined F1-score again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6da3132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combined_defence=np.concatenate((y_pred_defence, y_pred_noisy_defence, y_pred_colour_patch_defence, y_pred_other_patch_defence, y_pred_same_patch_defence, y_pred_cw_defence), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86bda378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8709262001405003\n"
     ]
    }
   ],
   "source": [
    "report_combined_defence=classification_report(test_labels_repeated, y_pred_combined_defence,output_dict=True)\n",
    "macro_f1_combined_defence = report_combined_defence['macro avg']['f1-score']\n",
    "print(macro_f1_combined_defence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92894e7",
   "metadata": {},
   "source": [
    "So we can see that in comparison to the basic CNN, the one with added defences saw a very large improvement on the CW adversarial images, but saw reductions to the F1-score in all of the other test sets. This very large improvement in the CW images meant that it performed better on the test set overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb57c8",
   "metadata": {},
   "source": [
    "## 4. No Classifier\n",
    "\n",
    "By combining the testing of the autoencoder and the adversarial classifier, we don't know what the effects of each were. We therefore created an extra CNN which was trained only on autoencoder outputs, no adversarial binary label, and will test this as well in order to compare the results to the full defences model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c8cad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "defences_cnn_no_class=tf.keras.models.load_model('defence_no_classifier200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37191778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 11s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_no_class = defences_cnn_no_class.predict(orig_test_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8cf014d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_no_class = np.argmax(y_pred_prob_no_class, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "711a71da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.60      0.72        60\n",
      "           1       0.91      0.97      0.94       720\n",
      "           2       0.91      0.90      0.91       750\n",
      "           3       0.84      0.91      0.87       450\n",
      "           4       0.94      0.90      0.92       660\n",
      "           5       0.85      0.91      0.88       630\n",
      "           6       0.97      0.69      0.80       150\n",
      "           7       0.91      0.84      0.87       450\n",
      "           8       0.89      0.86      0.87       450\n",
      "           9       0.96      0.93      0.94       480\n",
      "          10       0.98      0.98      0.98       660\n",
      "          11       0.94      0.97      0.96       420\n",
      "          12       0.99      0.98      0.99       690\n",
      "          13       1.00      1.00      1.00       720\n",
      "          14       1.00      1.00      1.00       270\n",
      "          15       0.94      0.98      0.96       210\n",
      "          16       0.99      1.00      1.00       150\n",
      "          17       1.00      0.99      1.00       360\n",
      "          18       0.90      0.88      0.89       390\n",
      "          19       0.85      0.95      0.90        60\n",
      "          20       0.67      0.86      0.75        90\n",
      "          21       1.00      0.57      0.72        90\n",
      "          22       0.92      0.90      0.91       120\n",
      "          23       0.76      0.87      0.81       150\n",
      "          24       0.92      0.78      0.84        90\n",
      "          25       0.93      0.95      0.94       480\n",
      "          26       0.81      0.93      0.87       180\n",
      "          27       0.60      0.50      0.55        60\n",
      "          28       0.94      0.90      0.92       150\n",
      "          29       0.87      0.98      0.92        90\n",
      "          30       0.84      0.65      0.73       150\n",
      "          31       0.93      0.95      0.94       270\n",
      "          32       1.00      1.00      1.00        60\n",
      "          33       0.93      1.00      0.97       210\n",
      "          34       0.94      1.00      0.97       120\n",
      "          35       0.98      0.98      0.98       390\n",
      "          36       0.97      0.96      0.96       120\n",
      "          37       0.98      0.95      0.97        60\n",
      "          38       0.99      0.99      0.99       690\n",
      "          39       0.99      0.80      0.88        90\n",
      "          40       0.95      0.91      0.93        90\n",
      "          41       0.97      0.98      0.98        60\n",
      "          42       0.69      0.94      0.79        90\n",
      "\n",
      "    accuracy                           0.93     12630\n",
      "   macro avg       0.91      0.90      0.90     12630\n",
      "weighted avg       0.93      0.93      0.93     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_pred_no_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d35ad1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9004759492978515\n"
     ]
    }
   ],
   "source": [
    "report_no_class=classification_report(test_labels, y_pred_no_class,output_dict=True)\n",
    "macro_f1_no_class = report_no_class['macro avg']['f1-score']\n",
    "print(macro_f1_no_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce5f77ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 10s 26ms/step\n",
      "0.8872441267727066\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_noisy_no_class = defences_cnn_no_class.predict(noisy_test_autoencoder)\n",
    "y_pred_noisy_no_class = np.argmax(y_pred_prob_noisy_no_class, axis=-1)\n",
    "report_noisy_no_class=classification_report(test_labels, y_pred_noisy_no_class,output_dict=True)\n",
    "macro_f1_noisy_no_class = report_noisy_no_class['macro avg']['f1-score']\n",
    "print(macro_f1_noisy_no_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e1a127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 10s 26ms/step\n",
      "0.851108092660862\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_colour_patch_no_class = defences_cnn_no_class.predict(colour_patch_test_autoencoder)\n",
    "y_pred_colour_patch_no_class = np.argmax(y_pred_prob_colour_patch_no_class, axis=-1)\n",
    "report_colour_patch_no_class=classification_report(test_labels, y_pred_colour_patch_no_class,output_dict=True)\n",
    "macro_f1_colour_patch_no_class = report_colour_patch_no_class['macro avg']['f1-score']\n",
    "print(macro_f1_colour_patch_no_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69b3a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 11s 27ms/step\n",
      "0.8559818387701263\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_other_patch_no_class = defences_cnn_no_class.predict(other_patch_test_autoencoder)\n",
    "y_pred_other_patch_no_class = np.argmax(y_pred_prob_other_patch_no_class, axis=-1)\n",
    "report_other_patch_no_class=classification_report(test_labels, y_pred_other_patch_no_class,output_dict=True)\n",
    "macro_f1_other_patch_no_class = report_other_patch_no_class['macro avg']['f1-score']\n",
    "print(macro_f1_other_patch_no_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7f6fd1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 10s 26ms/step\n",
      "0.8714061233428062\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_same_patch_no_class = defences_cnn_no_class.predict(same_patch_test_autoencoder)\n",
    "y_pred_same_patch_no_class = np.argmax(y_pred_prob_same_patch_no_class, axis=-1)\n",
    "report_same_patch_no_class=classification_report(test_labels, y_pred_same_patch_no_class,output_dict=True)\n",
    "macro_f1_same_patch_no_class = report_same_patch_no_class['macro avg']['f1-score']\n",
    "print(macro_f1_same_patch_no_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d49a9ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 10s 26ms/step\n",
      "0.8606667320155059\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_cw_no_class = defences_cnn_no_class.predict(cw_advs_test_autoencoder)\n",
    "y_pred_cw_no_class = np.argmax(y_pred_prob_cw_no_class, axis=-1)\n",
    "report_cw_no_class=classification_report(test_labels, y_pred_cw_no_class,output_dict=True)\n",
    "macro_f1_cw_no_class = report_cw_no_class['macro avg']['f1-score']\n",
    "print(macro_f1_cw_no_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a093e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combined_no_class=np.concatenate((y_pred_no_class, y_pred_noisy_no_class, y_pred_colour_patch_no_class, y_pred_other_patch_no_class, y_pred_same_patch_no_class, y_pred_cw_no_class), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da64c768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8711554757080944\n"
     ]
    }
   ],
   "source": [
    "report_combined_no_class=classification_report(test_labels_repeated, y_pred_combined_no_class,output_dict=True)\n",
    "macro_f1_combined_no_class = report_combined_no_class['macro avg']['f1-score']\n",
    "print(macro_f1_combined_no_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be4510",
   "metadata": {},
   "source": [
    "We find that the results of this model are essentially the same as the results from the full defences model. This implies that the classification of adversarial images provided no benefit to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d38902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
