{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee93cc2",
   "metadata": {},
   "source": [
    "# Classifying adversarial images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc85c8",
   "metadata": {},
   "source": [
    "In order to aid in the correct classification of traffic signs, we wanted to explore designing a binary classifier which could distinguish between adversarial images and untampered images. In this notebook, the class label 1 represents an adversarial image and the class label 0 represents an untampered image.\n",
    "As the noisy image attacks were to be dealt with by the denoiser, they are included in this notebook as non-adversary images (label 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2ea2a",
   "metadata": {},
   "source": [
    "The idea would be to run images through this classifier first, before inputting the images into the multiclass CNN. The output from this binary classifier would serve as an additional feature for the multiclass CNN and would advise on whether the image it was classifying has been perturbed to hopefully prevent misclassification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7ab66",
   "metadata": {},
   "source": [
    "First, import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb595346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(42)\n",
    "\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b43242",
   "metadata": {},
   "source": [
    "Next, define the file paths for the adversarial images and real images. If you would like to replicate this notebook, the adversarial images after being through the autoencoder can be found [here](https://drive.google.com/drive/u/0/folders/1tg24731_oseORhm1v2AMW-mOtC2wW8IJ). The untampered image npy file can be found [here](https://drive.google.com/drive/u/0/folders/1tg24731_oseORhm1v2AMW-mOtC2wW8IJ) and is called 'filter_denoised .npy'. Once downloaded, you can edit the file paths below to match your desktop file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa248320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#untampered dataset (with bright dark filter applied), stored as npy files within folders\n",
    "untampered = np.load('filter_denoised .npy')\n",
    "\n",
    "#adversarial image dataset, stored as 3 npy files - 3 types of adversarial attacks\n",
    "adv_data2 = np.load('black_patched_denoised.npy')\n",
    "adv_data3 = np.load('white_patched_denoised.npy')\n",
    "adv_data4 = np.load('same_image_patched_denoised.npy')\n",
    "noisy = np.load('noisy_train_denoised.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bf62cc",
   "metadata": {},
   "source": [
    "Next, we want to create an array which stores the class labels. We shall store 117627 1's to the labels array and append 78418 0's for the number of original images and noisy images. We are giving the noisy images a label of 0 for non-adversary as we assume that having been through the auotencoder, they will have had the noise removed. We then combine the adversary and untampered ndarrays to form one training set, before shuffling both the training set and labels (using the same index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "915ab0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(117627,dtype='float32')\n",
    "zeros = np.zeros(78418,dtype='float32')\n",
    "labels = np.concatenate((ones,zeros),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2ae26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.concatenate((adv_data2,adv_data3,adv_data4,untampered),axis=0,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da43d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.arange(training_set.shape[0])\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(s)\n",
    "training_set=training_set[s]\n",
    "labels=labels[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab2de3d",
   "metadata": {},
   "source": [
    "Here we create the train-validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6c78af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (109785, 32, 32, 3)\n",
      "X_valid.shape (47051, 32, 32, 3)\n",
      "y_train.shape (109785,)\n",
      "y_valid.shape (47051,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(training_set, labels, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "X_train = X_train\n",
    "X_val = X_val\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_valid.shape\", X_val.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"y_valid.shape\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafe41f6",
   "metadata": {},
   "source": [
    "Next we define the structure of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f04d2123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 30, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 3, 3, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               590336    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 723,713\n",
      "Trainable params: 722,369\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.Dropout(rate=0.4),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(), #normalises output mean close to 0\n",
    "    keras.layers.Dropout(rate=0.4),\n",
    "    \n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "    \n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db121716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Team Knowhow\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 1\n",
    "\n",
    "opt =tf.keras.optimizers.legacy.Adam(lr=lr, decay=lr / (epochs * 0.5))\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b3754b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3431/3431 [==============================] - 400s 115ms/step - loss: 0.5692 - accuracy: 0.7234 - val_loss: 0.4829 - val_accuracy: 0.7517\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "history = model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4288f3",
   "metadata": {},
   "source": [
    "A version of this notebook was ran for 200 epochs on the HPC and the resulting model was saved as adv_classifier_200.h5. This model had an accuracy of 78% on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783cab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc_env",
   "language": "python",
   "name": "hpc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
